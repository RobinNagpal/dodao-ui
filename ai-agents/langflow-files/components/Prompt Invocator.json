{
  "icon_bg_color": null,
  "user_id": "0be3e4c3-3b27-440f-81e4-921ccf9df0b3",
  "gradient": null,
  "icon": null,
  "is_component": true,
  "tags": null,
  "updated_at": "2025-04-07T18:29:12+00:00",
  "locked": false,
  "webhook": false,
  "folder_id": "00af9b7e-c33a-4fbf-8396-9739dbc109f2",
  "endpoint_name": null,
  "description": "A custom component for running a prompt using a prompt key.",
  "id": "778ffcc6-4a49-46b0-bb5c-54a204ba3d52",
  "name": "Prompt Invocator",
  "data": {
    "edges": [],
    "nodes": [
      {
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.inputs import DropdownInput\r\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\nfrom langflow.helpers.data import data_to_text\r\nimport requests\r\nimport json\r\n\r\nclass PromptInvocatorComponent(Component):\r\n    display_name = \"Prompt Invocator\"\r\n    description = \"A custom component for running a prompt using a prompt key.\"\r\n    documentation = \"https://docs.langflow.org/components-custom-components\"\r\n    icon = \"custom_components\"\r\n    name = \"PromptInvocator\"\r\n\r\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\r\n    \r\n    inputs = [\r\n        DataInput(\r\n            name=\"input_json\",\r\n            display_name=\"Input Json\",\r\n            info=\"The data to send to the prompt invocation.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"prompt_key\",\r\n            display_name=\"Prompt Key\",\r\n            info=\"The key added when creating the prompt.\",\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"agent_llm\",\r\n            display_name=\"LLM Provider\",\r\n            options=[\"OpenAI\"],\r\n            value=\"OpenAI\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"model\",\r\n            display_name=\"Model\",\r\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\"],\r\n            value=\"gpt-4o-mini\",\r\n        ),\r\n        MultilineInput(\r\n            name=\"body_to_append\",\r\n            display_name=\"Body To Append\",\r\n            info=\"Body to be appended after the prompt.\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"output_type\",\r\n            display_name=\"Output Type\",\r\n            options=[\"Data\", \"Message\"],\r\n            value=\"Data\",\r\n            info=\"Select the type of output returned by the component.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Data\",\r\n            name=\"invocation_output\",\r\n            method=\"output_data\",\r\n        ),\r\n        Output(\r\n            display_name=\"Message\",\r\n            name=\"text\",\r\n            method=\"output_message\",\r\n        ),\r\n    ]\r\n\r\n    def call_prompt_invocator(self) -> Data:\r\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\r\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\r\n        prompt_key = self.prompt_key\r\n        agent_llm = self.agent_llm\r\n        model = self.model\r\n        body_to_append = self.body_to_append\r\n\r\n        payload = {\r\n            \"inputJson\": input_json,\r\n            \"promptKey\": prompt_key,\r\n            \"llmProvider\": agent_llm,\r\n            \"model\": model,\r\n            \"bodyToAppend\": body_to_append,\r\n            \"requestFrom\": \"langflow\"\r\n        }\r\n        try:\r\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\r\n            try:\r\n                resp_data = response.json()\r\n            except json.JSONDecodeError:\r\n                resp_data = {\"raw_text\": response.text}\r\n            return Data(data=resp_data)\r\n        except Exception as exc:\r\n            return Data(data={\"error\": str(exc)})\r\n\r\n    def _get_invocation_result(self) -> Data:\r\n        \"\"\"\r\n        Cache the API call result so that we don't call it twice.\r\n        \"\"\"\r\n        if not hasattr(self, \"_result\"):\r\n            self._result = self.call_prompt_invocator()\r\n        return self._result\r\n\r\n    def output_data(self) -> Data:\r\n        \"\"\"\r\n        Returns the Data output if 'Data' is selected in the dropdown;\r\n        otherwise returns an empty Data.\r\n        \"\"\"\r\n        if self.output_type == \"Data\":\r\n            return self._get_invocation_result()\r\n        else:\r\n            return Data(data={})\r\n\r\n    def output_message(self) -> Message:\r\n        \"\"\"\r\n        Returns a Message output if 'Message' is selected in the dropdown;\r\n        otherwise returns an empty Message.\r\n        \"\"\"\r\n        if self.output_type == \"Message\":\r\n            data = self._get_invocation_result()\r\n            try:\r\n                result_string = data_to_text(\"{message}\", data)\r\n                return Message(text=result_string)\r\n            except Exception as exc:\r\n                return Message(text=str(exc))\r\n        else:\r\n            return Message(text=\"\")\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "gpt-4o-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Data",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/metrics",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "official": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-ijhU5"
        },
        "id": "PromptInvocator-ijhU5",
        "position": {
          "x": 0,
          "y": 0
        },
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 1,
      "y": 1,
      "zoom": 1
    }
  }
}