{
  "icon_bg_color": null,
  "user_id": "0be3e4c3-3b27-440f-81e4-921ccf9df0b3",
  "gradient": null,
  "icon": null,
  "is_component": false,
  "tags": null,
  "updated_at": "2025-08-06T14:13:29+00:00",
  "locked": false,
  "webhook": true,
  "folder_id": "00af9b7e-c33a-4fbf-8396-9739dbc109f2",
  "endpoint_name": null,
  "description": "Your Passport to Linguistic Landscapes.",
  "id": "402667f0-9cd9-45e2-87c1-c99cef4fbc63",
  "name": "Operational v3",
  "data": {
    "nodes": [
      {
        "id": "Prompt-PI1Wk",
        "type": "genericNode",
        "position": {
          "x": 6549.739343970497,
          "y": 3144.3860765684867
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "## All Financial Statements:\n\n{All_Financial_Data}\n---------------------------------------------------------------------------------\n## Related Information from SEC 10Q Filing:\n\n{Criterion}\n\n\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "Criterion": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "Criterion",
                "display_name": "Criterion",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "All_Financial_Data": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "All_Financial_Data",
                "display_name": "All_Financial_Data",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "All_Financial_Data",
                "Criterion"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-PI1Wk"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 420
        }
      },
      {
        "id": "SimpleAPIRequest-ESO4j",
        "type": "genericNode",
        "position": {
          "x": 10978.540113548854,
          "y": 2270.404724905538
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "body_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_data",
                "value": "",
                "display_name": "Body (JSON Data)",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Parsed JSON from the JSONPayloadComponent (or any Data).",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\r\nimport asyncio\r\nfrom typing import Any, Dict\r\n\r\nimport httpx\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (\r\n    StrInput,\r\n    DropdownInput,\r\n    DataInput,\r\n    Output,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass SimpleAPIRequestComponent(Component):\r\n    display_name = \"Simple API Request\"\r\n    description = \"Makes an HTTP request with JSON-based body input.\"\r\n    icon = \"Globe\"\r\n    name = \"SimpleAPIRequest\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"Enter the HTTP endpoint to call (e.g., https://api.example.com).\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\r\n            info=\"Select the HTTP method to use.\",\r\n        ),\r\n        DataInput(\r\n            name=\"body_data\",\r\n            display_name=\"Body (JSON Data)\",\r\n            info=\"Parsed JSON from the JSONPayloadComponent (or any Data).\",\r\n            advanced=False,\r\n        ),\r\n        TableInput(\r\n            name=\"headers_data\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary.\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Header\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header value\",\r\n                },\r\n            ],\r\n            value=[],\r\n            advanced=True,\r\n            input_types=[\"Data\"],\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Response\", name=\"response\", method=\"make_request\"),\r\n    ]\r\n\r\n    async def make_request(self) -> Data:\r\n        \"\"\"Executes an HTTP request using the provided URL, method, body_data, and headers_data.\"\"\"\r\n        url = self.url\r\n        method = self.method.upper()\r\n\r\n        # Extract the actual data from the Data objects\r\n        # If \"body_data\" was from JSONPayloadComponent, it might be a dict or a string.\r\n        # We'll assume dictionary is intended for JSON body. If it's something else, handle gracefully.\r\n        body_content = self.body_data.data if self.body_data else None\r\n        if not isinstance(body_content, (dict, list)) and body_content is not None:\r\n            # If it's a plain string or something else, wrap it or parse it as needed\r\n            # For a real app, you could refine this logic. For now, we'll just send it as-is.\r\n            body_content = {\"data\": body_content}\r\n\r\n        # Same for headers\r\n        headers = {}\r\n        if self.headers_data and isinstance(self.headers_data.data, dict):\r\n            # Convert all header values to strings just to be safe\r\n            headers = {str(k): str(v) for k, v in self.headers_data.data.items()}\r\n\r\n        try:\r\n            async with httpx.AsyncClient() as client:\r\n                if method in {\"GET\", \"DELETE\"}:\r\n                    # GET/DELETE usually send no JSON body\r\n                    response = await client.request(method, url, headers=headers)\r\n                else:\r\n                    response = await client.request(method, url, headers=headers, json=body_content)\r\n\r\n                # Attempt to parse the response as JSON\r\n                try:\r\n                    resp_data = response.json()\r\n                except json.JSONDecodeError:\r\n                    # If not valid JSON, just return the raw text\r\n                    resp_data = {\"raw_text\": response.text}\r\n\r\n                return Data(\r\n                    data={\r\n                        \"status_code\": response.status_code,\r\n                        \"response\": resp_data,\r\n                    }\r\n                )\r\n\r\n        except Exception as exc:\r\n            # If there's a network error, timeouts, etc., return an error structure\r\n            return Data(\r\n                    data={\r\n                        \"status_code\": 500,\r\n                        \"response\": str(exc),\r\n                    }\r\n                )\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "headers_data": {
                "tool_mode": false,
                "is_list": true,
                "list_add_label": "Add More",
                "table_schema": {
                  "columns": [
                    {
                      "name": "key",
                      "display_name": "Header",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header name",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    },
                    {
                      "name": "value",
                      "display_name": "Value",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header value",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    }
                  ]
                },
                "trigger_text": "Open table",
                "trigger_icon": "Table",
                "table_icon": "Table",
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "headers_data",
                "value": [],
                "display_name": "Headers",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "method": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "method",
                "value": "POST",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "Select the HTTP method to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "url": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "SAVE_METRICS",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the HTTP endpoint to call (e.g., https://api.example.com).",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Makes an HTTP request with JSON-based body input.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "Simple API Request",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "make_request",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "url",
              "method",
              "body_data",
              "headers_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "SimpleAPIRequest",
          "id": "SimpleAPIRequest-ESO4j"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        }
      },
      {
        "id": "SimpleAPIRequest-OZt8Y",
        "type": "genericNode",
        "position": {
          "x": 12276.419367806371,
          "y": 571.1339728989469
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "body_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_data",
                "value": "",
                "display_name": "Body (JSON Data)",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Parsed JSON from the JSONPayloadComponent (or any Data).",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\r\nimport asyncio\r\nfrom typing import Any, Dict\r\n\r\nimport httpx\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (\r\n    StrInput,\r\n    DropdownInput,\r\n    DataInput,\r\n    Output,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass SimpleAPIRequestComponent(Component):\r\n    display_name = \"Simple API Request\"\r\n    description = \"Makes an HTTP request with JSON-based body input.\"\r\n    icon = \"Globe\"\r\n    name = \"SimpleAPIRequest\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"Enter the HTTP endpoint to call (e.g., https://api.example.com).\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\r\n            info=\"Select the HTTP method to use.\",\r\n        ),\r\n        DataInput(\r\n            name=\"body_data\",\r\n            display_name=\"Body (JSON Data)\",\r\n            info=\"Parsed JSON from the JSONPayloadComponent (or any Data).\",\r\n            advanced=False,\r\n        ),\r\n        TableInput(\r\n            name=\"headers_data\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary.\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Header\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header value\",\r\n                },\r\n            ],\r\n            value=[],\r\n            advanced=True,\r\n            input_types=[\"Data\"],\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Response\", name=\"response\", method=\"make_request\"),\r\n    ]\r\n\r\n    async def make_request(self) -> Data:\r\n        \"\"\"Executes an HTTP request using the provided URL, method, body_data, and headers_data.\"\"\"\r\n        url = self.url\r\n        method = self.method.upper()\r\n\r\n        # Extract the actual data from the Data objects\r\n        # If \"body_data\" was from JSONPayloadComponent, it might be a dict or a string.\r\n        # We'll assume dictionary is intended for JSON body. If it's something else, handle gracefully.\r\n        body_content = self.body_data.data if self.body_data else None\r\n        if not isinstance(body_content, (dict, list)) and body_content is not None:\r\n            # If it's a plain string or something else, wrap it or parse it as needed\r\n            # For a real app, you could refine this logic. For now, we'll just send it as-is.\r\n            body_content = {\"data\": body_content}\r\n\r\n        # Same for headers\r\n        headers = {}\r\n        if self.headers_data and isinstance(self.headers_data.data, dict):\r\n            # Convert all header values to strings just to be safe\r\n            headers = {str(k): str(v) for k, v in self.headers_data.data.items()}\r\n\r\n        try:\r\n            async with httpx.AsyncClient() as client:\r\n                if method in {\"GET\", \"DELETE\"}:\r\n                    # GET/DELETE usually send no JSON body\r\n                    response = await client.request(method, url, headers=headers)\r\n                else:\r\n                    response = await client.request(method, url, headers=headers, json=body_content)\r\n\r\n                # Attempt to parse the response as JSON\r\n                try:\r\n                    resp_data = response.json()\r\n                except json.JSONDecodeError:\r\n                    # If not valid JSON, just return the raw text\r\n                    resp_data = {\"raw_text\": response.text}\r\n\r\n                return Data(\r\n                    data={\r\n                        \"status_code\": response.status_code,\r\n                        \"response\": resp_data,\r\n                    }\r\n                )\r\n\r\n        except Exception as exc:\r\n            # If there's a network error, timeouts, etc., return an error structure\r\n            return Data(\r\n                    data={\r\n                        \"status_code\": 500,\r\n                        \"response\": str(exc),\r\n                    }\r\n                )\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "headers_data": {
                "tool_mode": false,
                "is_list": true,
                "list_add_label": "Add More",
                "table_schema": {
                  "columns": [
                    {
                      "name": "key",
                      "display_name": "Header",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header name",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    },
                    {
                      "name": "value",
                      "display_name": "Value",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header value",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    }
                  ]
                },
                "trigger_text": "Open table",
                "trigger_icon": "Table",
                "table_icon": "Table",
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "headers_data",
                "value": [],
                "display_name": "Headers",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "method": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "method",
                "value": "POST",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "Select the HTTP method to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "url": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "SAVE_PERFORMANCE_CHECKLIST",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the HTTP endpoint to call (e.g., https://api.example.com).",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Makes an HTTP request with JSON-based body input.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "Simple API Request",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "make_request",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "url",
              "method",
              "body_data",
              "headers_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "SimpleAPIRequest",
          "id": "SimpleAPIRequest-OZt8Y"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        }
      },
      {
        "id": "Sec10QDataExtractor-AHeLe",
        "type": "genericNode",
        "position": {
          "x": 6104.010285502902,
          "y": 2649.734311611608
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\nfrom langflow.io import MessageTextInput, Output\n\nimport requests\nimport json\n\n\"\"\"\nThis module defines a single custom component (`SecEdgarMergedComponent`) that merges\nthree different \"tools\" or functionalities for retrieving SEC 10-Q filings data:\n\n1) **All Financials (mode='all_financials')**  \n   - Retrieves the full 10-Q XBRL-based financial statements for a given ticker.\n\n2) **Specific 10-Q Report (mode='specific_report')**  \n   - Retrieves a specific part of the 10-Q for a given ticker.  \n   - e.g. 'balance_sheet', 'income_statement', etc.\n\n3) **Criteria-Related Info (mode='criteria_related_info')**  \n   - Retrieves data related to a given \"criterion\" (e.g., 'debt', 'rent') in the 10-Q.\n\n-------------------------------------------------------------------------------\nExample System Prompt (to guide the LLM on how to choose the 'mode' & inputs):\n\n\"You have a single custom SEC 10-Q data extractor tool that has 3 possible modes:\n1) 'all_financials' for full 10-Q financial data,\n2) 'specific_report' for a specific 10-Q section (balance_sheet, income_statement, etc.),\n3) 'criteria_related_info' for retrieving specific criteria.\n\nWhen a user asks for the full 10-Q financial statements, set mode='all_financials'.\nWhen a user asks for a specific statement, set mode='specific_report' and fill 'report_type'.\nWhen a user asks for a custom criterion, set mode='criteria_related_info' and fill 'criterion_key'.\nAlways set 'ticker' according to the user's request.\"\n\n-------------------------------------------------------------------------------\nExample User Prompts that will route to the correct mode:\n\n1) \"Give me the info of debt criteria of AMT in sec filing.\"\n   \"Find me info on lease obligations for AMT's latest 10-Q.\"\n   -> mode='criteria_related_info', ticker='AMT', criterion_key='debt'\n\n2) \"Give me all financial details of AMT stock in sec filing.\"\n   \"Please fetch all 10-Q financial data for AMT.\"\n   -> mode='all_financials', ticker='AMT'\n\n3) \"Give me balance sheet of AMT stock in sec filing.\"\n   \"Show me the balance sheet of AMT's latest 10-Q.\"\n   -> mode='specific_report', ticker='AMT', report_type='balance_sheet'\n\n-------------------------------------------------------------------------------\n\"\"\"\n\nclass SecEdgarMergedComponent(Component):\n    display_name = \"SEC 10-Q Data\"\n    description = \"A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"Sec10QDataExtractor\"\n\n    FINANCIALS_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/financials\"\n    SEARCH_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/search\"\n    CRITERIA_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/get-matching-criteria-attachments\"\n    \n    inputs = [\n        MessageTextInput(\n            name=\"ticker\",\n            display_name=\"Ticker\",\n            value=\"AAPL\",\n            info=\"The stock ticker symbol (e.g. AAPL).\",\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"all_financials\", \"specific_report\", \"criteria_related_info\"],\n            info=(\n                \"Select 'all_financials' to retrieve the full 10Q XBRL-based data.\\n\"\n                \"Select 'specific_report' to retrieve a specific part of the 10Q.\\n\"\n                \"Select 'criteria_related_info' to retrieve specific criterion data from the 10Q.\"\n            ),\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"report_type\",\n            display_name=\"Report Type (Used if mode='specific_report')\",\n            value=\"\",\n            info=\"E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"criterion_key\",\n            display_name=\"Criterion Key (Used if mode='criteria_related_info')\",\n            value=\"\",\n            info=\"Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Merged SEC Output\",\n            name=\"merged_sec_output\",\n            method=\"call_merged_tool\",\n        )\n    ]\n\n    def call_merged_tool(self) -> Message:\n        \"\"\"\n        Decide which underlying call to run based on 'mode'.\n        For PART 1, we'll return placeholder text.\n        Replace this with real Lambda calls in PART 2.\n        \"\"\"\n\n        ticker = self.ticker\n        mode = self.mode\n        report_type = self.report_type\n        criterion_key = self.criterion_key\n\n        if mode == \"all_financials\":\n            return self._call_all_financials(ticker)\n\n        elif mode == \"specific_report\":\n            return self._call_specific_report(ticker, report_type)\n        \n        elif mode == \"criteria_related_info\":\n            return self._call_criteria_info(ticker, criterion_key)\n\n        else:\n            return Message(\n                text=(\n                    f\"You selected mode '{mode}', which isn't implemented yet.\\n\"\n                    \"In the future, we can add new routes or logic here.\"\n                )\n            )\n\n    def _call_all_financials(self, ticker: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker}\n            response = requests.post(self.FINANCIALS_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/financials): {e}\"\n            return Message(text=error_text)\n\n    def _call_specific_report(self, ticker: str, report_type: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"report_type\": report_type}\n            response = requests.post(self.SEARCH_ENDPOINT, json=payload)\n            data = response.json()  \n\n            message_text = data.get(\"data\", \"\")\n            return Message(text=message_text)\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/search): {e}\"\n            return Message(text=error_text)\n\n    def _call_criteria_info(self, ticker: str, criterion_key: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"criterion_key\": criterion_key}\n            response = requests.post(self.CRITERIA_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/get-matching-criteria-attachments): {e}\"\n            return Message(text=error_text)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "criterion_key": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "criterion_key",
                "value": "",
                "display_name": "Criterion Key (Used if mode='criteria_related_info')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mode": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "all_financials",
                  "specific_report",
                  "criteria_related_info"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mode",
                "value": "all_financials",
                "display_name": "Mode",
                "advanced": false,
                "dynamic": false,
                "info": "Select 'all_financials' to retrieve the full 10Q XBRL-based data.\nSelect 'specific_report' to retrieve a specific part of the 10Q.\nSelect 'criteria_related_info' to retrieve specific criterion data from the 10Q.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "report_type": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "report_type",
                "value": "",
                "display_name": "Report Type (Used if mode='specific_report')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "ticker": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ticker",
                "value": "",
                "display_name": "Ticker",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The stock ticker symbol (e.g. AAPL).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "SEC 10-Q Data",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "merged_sec_output",
                "hidden": null,
                "display_name": "Merged SEC Output",
                "method": "call_merged_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "ticker",
              "mode",
              "report_type",
              "criterion_key"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "Sec10QDataExtractor",
          "id": "Sec10QDataExtractor-AHeLe"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 517
        }
      },
      {
        "id": "Sec10QDataExtractor-wVpsv",
        "type": "genericNode",
        "position": {
          "x": 6130.548559899203,
          "y": 3488.9411223950024
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\nfrom langflow.io import MessageTextInput, Output\n\nimport requests\nimport json\n\n\"\"\"\nThis module defines a single custom component (`SecEdgarMergedComponent`) that merges\nthree different \"tools\" or functionalities for retrieving SEC 10-Q filings data:\n\n1) **All Financials (mode='all_financials')**  \n   - Retrieves the full 10-Q XBRL-based financial statements for a given ticker.\n\n2) **Specific 10-Q Report (mode='specific_report')**  \n   - Retrieves a specific part of the 10-Q for a given ticker.  \n   - e.g. 'balance_sheet', 'income_statement', etc.\n\n3) **Criteria-Related Info (mode='criteria_related_info')**  \n   - Retrieves data related to a given \"criterion\" (e.g., 'debt', 'rent') in the 10-Q.\n\n-------------------------------------------------------------------------------\nExample System Prompt (to guide the LLM on how to choose the 'mode' & inputs):\n\n\"You have a single custom SEC 10-Q data extractor tool that has 3 possible modes:\n1) 'all_financials' for full 10-Q financial data,\n2) 'specific_report' for a specific 10-Q section (balance_sheet, income_statement, etc.),\n3) 'criteria_related_info' for retrieving specific criteria.\n\nWhen a user asks for the full 10-Q financial statements, set mode='all_financials'.\nWhen a user asks for a specific statement, set mode='specific_report' and fill 'report_type'.\nWhen a user asks for a custom criterion, set mode='criteria_related_info' and fill 'criterion_key'.\nAlways set 'ticker' according to the user's request.\"\n\n-------------------------------------------------------------------------------\nExample User Prompts that will route to the correct mode:\n\n1) \"Give me the info of debt criteria of AMT in sec filing.\"\n   \"Find me info on lease obligations for AMT's latest 10-Q.\"\n   -> mode='criteria_related_info', ticker='AMT', criterion_key='debt'\n\n2) \"Give me all financial details of AMT stock in sec filing.\"\n   \"Please fetch all 10-Q financial data for AMT.\"\n   -> mode='all_financials', ticker='AMT'\n\n3) \"Give me balance sheet of AMT stock in sec filing.\"\n   \"Show me the balance sheet of AMT's latest 10-Q.\"\n   -> mode='specific_report', ticker='AMT', report_type='balance_sheet'\n\n-------------------------------------------------------------------------------\n\"\"\"\n\nclass SecEdgarMergedComponent(Component):\n    display_name = \"SEC 10-Q Data\"\n    description = \"A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"Sec10QDataExtractor\"\n\n    FINANCIALS_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/financials\"\n    SEARCH_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/search\"\n    CRITERIA_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/get-matching-criteria-attachments\"\n    \n    inputs = [\n        MessageTextInput(\n            name=\"ticker\",\n            display_name=\"Ticker\",\n            value=\"AAPL\",\n            info=\"The stock ticker symbol (e.g. AAPL).\",\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"all_financials\", \"specific_report\", \"criteria_related_info\"],\n            info=(\n                \"Select 'all_financials' to retrieve the full 10Q XBRL-based data.\\n\"\n                \"Select 'specific_report' to retrieve a specific part of the 10Q.\\n\"\n                \"Select 'criteria_related_info' to retrieve specific criterion data from the 10Q.\"\n            ),\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"report_type\",\n            display_name=\"Report Type (Used if mode='specific_report')\",\n            value=\"\",\n            info=\"E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"criterion_key\",\n            display_name=\"Criterion Key (Used if mode='criteria_related_info')\",\n            value=\"\",\n            info=\"Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Merged SEC Output\",\n            name=\"merged_sec_output\",\n            method=\"call_merged_tool\",\n        )\n    ]\n\n    def call_merged_tool(self) -> Message:\n        \"\"\"\n        Decide which underlying call to run based on 'mode'.\n        For PART 1, we'll return placeholder text.\n        Replace this with real Lambda calls in PART 2.\n        \"\"\"\n\n        ticker = self.ticker\n        mode = self.mode\n        report_type = self.report_type\n        criterion_key = self.criterion_key\n\n        if mode == \"all_financials\":\n            return self._call_all_financials(ticker)\n\n        elif mode == \"specific_report\":\n            return self._call_specific_report(ticker, report_type)\n        \n        elif mode == \"criteria_related_info\":\n            return self._call_criteria_info(ticker, criterion_key)\n\n        else:\n            return Message(\n                text=(\n                    f\"You selected mode '{mode}', which isn't implemented yet.\\n\"\n                    \"In the future, we can add new routes or logic here.\"\n                )\n            )\n\n    def _call_all_financials(self, ticker: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker}\n            response = requests.post(self.FINANCIALS_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/financials): {e}\"\n            return Message(text=error_text)\n\n    def _call_specific_report(self, ticker: str, report_type: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"report_type\": report_type}\n            response = requests.post(self.SEARCH_ENDPOINT, json=payload)\n            data = response.json()  \n\n            message_text = data.get(\"data\", \"\")\n            return Message(text=message_text)\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/search): {e}\"\n            return Message(text=error_text)\n\n    def _call_criteria_info(self, ticker: str, criterion_key: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"criterion_key\": criterion_key}\n            response = requests.post(self.CRITERIA_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/get-matching-criteria-attachments): {e}\"\n            return Message(text=error_text)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "criterion_key": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "criterion_key",
                "value": "",
                "display_name": "Criterion Key (Used if mode='criteria_related_info')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mode": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "all_financials",
                  "specific_report",
                  "criteria_related_info"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mode",
                "value": "criteria_related_info",
                "display_name": "Mode",
                "advanced": false,
                "dynamic": false,
                "info": "Select 'all_financials' to retrieve the full 10Q XBRL-based data.\nSelect 'specific_report' to retrieve a specific part of the 10Q.\nSelect 'criteria_related_info' to retrieve specific criterion data from the 10Q.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "report_type": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "report_type",
                "value": "",
                "display_name": "Report Type (Used if mode='specific_report')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "ticker": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ticker",
                "value": "",
                "display_name": "Ticker",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The stock ticker symbol (e.g. AAPL).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "SEC 10-Q Data",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "merged_sec_output",
                "hidden": null,
                "display_name": "Merged SEC Output",
                "method": "call_merged_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "ticker",
              "mode",
              "report_type",
              "criterion_key"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "Sec10QDataExtractor",
          "id": "Sec10QDataExtractor-wVpsv"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 517
        }
      },
      {
        "id": "note-XxPeT",
        "type": "noteNode",
        "position": {
          "x": 11006.141947261644,
          "y": 45
        },
        "data": {
          "node": {
            "description": "# Performance Checklist",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-XxPeT"
        },
        "selected": false,
        "measured": {
          "width": 325,
          "height": 324
        }
      },
      {
        "id": "note-kCPFn",
        "type": "noteNode",
        "position": {
          "x": 11601.668839487978,
          "y": 2136.204406496785
        },
        "data": {
          "node": {
            "description": "# Important Metrics",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-kCPFn"
        },
        "selected": false,
        "measured": {
          "width": 325,
          "height": 324
        }
      },
      {
        "id": "SimpleAPIRequest-QMuQt",
        "type": "genericNode",
        "position": {
          "x": 9399.56371037977,
          "y": 5680.935861922915
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "body_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_data",
                "value": "",
                "display_name": "Body (JSON Data)",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Parsed JSON from the JSONPayloadComponent (or any Data).",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\r\nimport asyncio\r\nfrom typing import Any, Dict\r\n\r\nimport httpx\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (\r\n    StrInput,\r\n    DropdownInput,\r\n    DataInput,\r\n    Output,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass SimpleAPIRequestComponent(Component):\r\n    display_name = \"Simple API Request\"\r\n    description = \"Makes an HTTP request with JSON-based body input.\"\r\n    icon = \"Globe\"\r\n    name = \"SimpleAPIRequest\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"Enter the HTTP endpoint to call (e.g., https://api.example.com).\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\r\n            info=\"Select the HTTP method to use.\",\r\n        ),\r\n        DataInput(\r\n            name=\"body_data\",\r\n            display_name=\"Body (JSON Data)\",\r\n            info=\"Parsed JSON from the JSONPayloadComponent (or any Data).\",\r\n            advanced=False,\r\n        ),\r\n        TableInput(\r\n            name=\"headers_data\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary.\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Header\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header value\",\r\n                },\r\n            ],\r\n            value=[],\r\n            advanced=True,\r\n            input_types=[\"Data\"],\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Response\", name=\"response\", method=\"make_request\"),\r\n    ]\r\n\r\n    async def make_request(self) -> Data:\r\n        \"\"\"Executes an HTTP request using the provided URL, method, body_data, and headers_data.\"\"\"\r\n        url = self.url\r\n        method = self.method.upper()\r\n\r\n        # Extract the actual data from the Data objects\r\n        # If \"body_data\" was from JSONPayloadComponent, it might be a dict or a string.\r\n        # We'll assume dictionary is intended for JSON body. If it's something else, handle gracefully.\r\n        body_content = self.body_data.data if self.body_data else None\r\n        if not isinstance(body_content, (dict, list)) and body_content is not None:\r\n            # If it's a plain string or something else, wrap it or parse it as needed\r\n            # For a real app, you could refine this logic. For now, we'll just send it as-is.\r\n            body_content = {\"data\": body_content}\r\n\r\n        # Same for headers\r\n        headers = {}\r\n        if self.headers_data and isinstance(self.headers_data.data, dict):\r\n            # Convert all header values to strings just to be safe\r\n            headers = {str(k): str(v) for k, v in self.headers_data.data.items()}\r\n\r\n        try:\r\n            async with httpx.AsyncClient() as client:\r\n                if method in {\"GET\", \"DELETE\"}:\r\n                    # GET/DELETE usually send no JSON body\r\n                    response = await client.request(method, url, headers=headers)\r\n                else:\r\n                    response = await client.request(method, url, headers=headers, json=body_content)\r\n\r\n                # Attempt to parse the response as JSON\r\n                try:\r\n                    resp_data = response.json()\r\n                except json.JSONDecodeError:\r\n                    # If not valid JSON, just return the raw text\r\n                    resp_data = {\"raw_text\": response.text}\r\n\r\n                return Data(\r\n                    data={\r\n                        \"status_code\": response.status_code,\r\n                        \"response\": resp_data,\r\n                    }\r\n                )\r\n\r\n        except Exception as exc:\r\n            # If there's a network error, timeouts, etc., return an error structure\r\n            return Data(\r\n                    data={\r\n                        \"status_code\": 500,\r\n                        \"response\": str(exc),\r\n                    }\r\n                )\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "headers_data": {
                "tool_mode": false,
                "is_list": true,
                "list_add_label": "Add More",
                "table_schema": {
                  "columns": [
                    {
                      "name": "key",
                      "display_name": "Header",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header name",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    },
                    {
                      "name": "value",
                      "display_name": "Value",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header value",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    }
                  ]
                },
                "trigger_text": "Open table",
                "trigger_icon": "Table",
                "table_icon": "Table",
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "headers_data",
                "value": [],
                "display_name": "Headers",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "method": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "method",
                "value": "POST",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "Select the HTTP method to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "url": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "SAVE_REPORT",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the HTTP endpoint to call (e.g., https://api.example.com).",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Makes an HTTP request with JSON-based body input.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "Simple API Request",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "make_request",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "url",
              "method",
              "body_data",
              "headers_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "SimpleAPIRequest",
          "id": "SimpleAPIRequest-QMuQt"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        }
      },
      {
        "id": "ConditionalRouter-NGeyN",
        "type": "genericNode",
        "position": {
          "x": 7917.545130214645,
          "y": 1461.4174041221777
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "case_sensitive",
                "value": false,
                "display_name": "Case Sensitive",
                "advanced": false,
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_route": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_route",
                "value": "false_result",
                "display_name": "Default Route",
                "advanced": true,
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "input_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "match_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "match_text",
                "value": "performance_and_metrics",
                "display_name": "Match Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text input to compare against.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 10,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "message": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to pass through either route.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "operator": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "operator",
                "value": "contains",
                "display_name": "Operator",
                "advanced": false,
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "icon": "split",
            "base_classes": [
              "Message"
            ],
            "display_name": "If-Else",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "true_result",
                "hidden": null,
                "display_name": "True",
                "method": "true_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "false_result",
                "hidden": null,
                "display_name": "False",
                "method": "false_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "logic",
            "key": "ConditionalRouter",
            "score": 0.001,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "ConditionalRouter",
          "id": "ConditionalRouter-NGeyN"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 588
        }
      },
      {
        "id": "ConditionalRouter-w9jsD",
        "type": "genericNode",
        "position": {
          "x": 7950.67705350916,
          "y": 4668.792030675145
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "case_sensitive",
                "value": false,
                "display_name": "Case Sensitive",
                "advanced": false,
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_route": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_route",
                "value": "false_result",
                "display_name": "Default Route",
                "advanced": true,
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "input_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "match_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "match_text",
                "value": "expense_breakdown_chart",
                "display_name": "Match Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text input to compare against.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 10,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "message": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to pass through either route.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "operator": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "operator",
                "value": "contains",
                "display_name": "Operator",
                "advanced": false,
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "icon": "split",
            "base_classes": [
              "Message"
            ],
            "display_name": "If-Else",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "true_result",
                "hidden": null,
                "display_name": "True",
                "method": "true_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "false_result",
                "hidden": null,
                "display_name": "False",
                "method": "false_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "logic",
            "key": "ConditionalRouter",
            "score": 0.001,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "ConditionalRouter",
          "id": "ConditionalRouter-w9jsD"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 588
        }
      },
      {
        "id": "Prompt-AdYS6",
        "type": "genericNode",
        "position": {
          "x": 11452.420283075617,
          "y": 509.3325934862578
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "# **Calculated Values of the Metrics:**\n\n{metricsValues}\n\n# **Supporting Financial and Operational Data:**\n\n{data}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "data": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "data",
                "display_name": "data",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "metricsValues": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "metricsValues",
                "display_name": "metricsValues",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "metricsValues",
                "data"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-AdYS6"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 420
        }
      },
      {
        "id": "Prompt-OKKM2",
        "type": "genericNode",
        "position": {
          "x": 10066.202680034658,
          "y": 2151.446634559756
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "# Price per share:\n\nPrice per share = $ {price}\n-------------------------------------------------------------------\n#  Lease defaults and payment failures\n\nUse below data to fill in the lease defaults and payment failures total score:\n{lease_default}\n--------------------------------------------------------------------------------\n# Expense Management Score\n\nBelow is all expenses and i have normalized it with revenue. use these to come up with the Expense Management Score. do not include any other expense other than the ones in this table:\n{expenses_ratio}\n-----------------------------------------------------------------------------------------\n# FFO per Share\n\nBelow is the data you will use to extract the FFO per Share\n{ffo_per_share}\n-----------------------------------------------------------------------------------------------\n# FFO to Equity Ratio\n\nBelow is the data you will use to extract ffo to equity ratio:\n{ffo_to_equity_ratio}\n---------------------------------------------------------------------------------------------------\n# Non-Cash Expense Score\n\nBelow is the data that you will use to extract the Non-Cash Expense Score\n{non_cash_expense_score}\n--------------------------------------------------------------------------------------------\n# Other Supporting Data:\n\nAnd here is the supporting data, including financial statements and FFO/AFFO details:\n{data}\n--------------------------------------------------------------------------------------------",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "data": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "data",
                "display_name": "data",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "expenses_ratio": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "expenses_ratio",
                "display_name": "expenses_ratio",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "lease_default": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "lease_default",
                "display_name": "lease_default",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "price": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "price",
                "display_name": "price",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "ffo_per_share": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "ffo_per_share",
                "display_name": "ffo_per_share",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "ffo_to_equity_ratio": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "ffo_to_equity_ratio",
                "display_name": "ffo_to_equity_ratio",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "non_cash_expense_score": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "non_cash_expense_score",
                "display_name": "non_cash_expense_score",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "price",
                "lease_default",
                "expenses_ratio",
                "ffo_per_share",
                "ffo_to_equity_ratio",
                "non_cash_expense_score",
                "data"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-OKKM2"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 832
        }
      },
      {
        "id": "ConditionalRouter-bUTeX",
        "type": "genericNode",
        "position": {
          "x": 7956.196532386826,
          "y": 6120.840958994408
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "case_sensitive",
                "value": false,
                "display_name": "Case Sensitive",
                "advanced": false,
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_route": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_route",
                "value": "false_result",
                "display_name": "Default Route",
                "advanced": true,
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "input_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "match_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "match_text",
                "value": "ffo_affo_summary_report",
                "display_name": "Match Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text input to compare against.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 10,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "message": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to pass through either route.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "operator": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "operator",
                "value": "contains",
                "display_name": "Operator",
                "advanced": false,
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "icon": "split",
            "base_classes": [
              "Message"
            ],
            "display_name": "If-Else",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "true_result",
                "hidden": null,
                "display_name": "True",
                "method": "true_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "false_result",
                "hidden": null,
                "display_name": "False",
                "method": "false_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "logic",
            "key": "ConditionalRouter",
            "score": 0.001,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "ConditionalRouter",
          "id": "ConditionalRouter-bUTeX"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 588
        }
      },
      {
        "id": "SimpleAPIRequest-2rGPs",
        "type": "genericNode",
        "position": {
          "x": 9475.965466666272,
          "y": 6403.813493973673
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "body_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_data",
                "value": "",
                "display_name": "Body (JSON Data)",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Parsed JSON from the JSONPayloadComponent (or any Data).",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\r\nimport asyncio\r\nfrom typing import Any, Dict\r\n\r\nimport httpx\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (\r\n    StrInput,\r\n    DropdownInput,\r\n    DataInput,\r\n    Output,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass SimpleAPIRequestComponent(Component):\r\n    display_name = \"Simple API Request\"\r\n    description = \"Makes an HTTP request with JSON-based body input.\"\r\n    icon = \"Globe\"\r\n    name = \"SimpleAPIRequest\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"Enter the HTTP endpoint to call (e.g., https://api.example.com).\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\r\n            info=\"Select the HTTP method to use.\",\r\n        ),\r\n        DataInput(\r\n            name=\"body_data\",\r\n            display_name=\"Body (JSON Data)\",\r\n            info=\"Parsed JSON from the JSONPayloadComponent (or any Data).\",\r\n            advanced=False,\r\n        ),\r\n        TableInput(\r\n            name=\"headers_data\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary.\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Header\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header value\",\r\n                },\r\n            ],\r\n            value=[],\r\n            advanced=True,\r\n            input_types=[\"Data\"],\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Response\", name=\"response\", method=\"make_request\"),\r\n    ]\r\n\r\n    async def make_request(self) -> Data:\r\n        \"\"\"Executes an HTTP request using the provided URL, method, body_data, and headers_data.\"\"\"\r\n        url = self.url\r\n        method = self.method.upper()\r\n\r\n        # Extract the actual data from the Data objects\r\n        # If \"body_data\" was from JSONPayloadComponent, it might be a dict or a string.\r\n        # We'll assume dictionary is intended for JSON body. If it's something else, handle gracefully.\r\n        body_content = self.body_data.data if self.body_data else None\r\n        if not isinstance(body_content, (dict, list)) and body_content is not None:\r\n            # If it's a plain string or something else, wrap it or parse it as needed\r\n            # For a real app, you could refine this logic. For now, we'll just send it as-is.\r\n            body_content = {\"data\": body_content}\r\n\r\n        # Same for headers\r\n        headers = {}\r\n        if self.headers_data and isinstance(self.headers_data.data, dict):\r\n            # Convert all header values to strings just to be safe\r\n            headers = {str(k): str(v) for k, v in self.headers_data.data.items()}\r\n\r\n        try:\r\n            async with httpx.AsyncClient() as client:\r\n                if method in {\"GET\", \"DELETE\"}:\r\n                    # GET/DELETE usually send no JSON body\r\n                    response = await client.request(method, url, headers=headers)\r\n                else:\r\n                    response = await client.request(method, url, headers=headers, json=body_content)\r\n\r\n                # Attempt to parse the response as JSON\r\n                try:\r\n                    resp_data = response.json()\r\n                except json.JSONDecodeError:\r\n                    # If not valid JSON, just return the raw text\r\n                    resp_data = {\"raw_text\": response.text}\r\n\r\n                return Data(\r\n                    data={\r\n                        \"status_code\": response.status_code,\r\n                        \"response\": resp_data,\r\n                    }\r\n                )\r\n\r\n        except Exception as exc:\r\n            # If there's a network error, timeouts, etc., return an error structure\r\n            return Data(\r\n                    data={\r\n                        \"status_code\": 500,\r\n                        \"response\": str(exc),\r\n                    }\r\n                )\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "headers_data": {
                "tool_mode": false,
                "is_list": true,
                "list_add_label": "Add More",
                "table_schema": {
                  "columns": [
                    {
                      "name": "key",
                      "display_name": "Header",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header name",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    },
                    {
                      "name": "value",
                      "display_name": "Value",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header value",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    }
                  ]
                },
                "trigger_text": "Open table",
                "trigger_icon": "Table",
                "table_icon": "Table",
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "headers_data",
                "value": [],
                "display_name": "Headers",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "method": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "method",
                "value": "POST",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "Select the HTTP method to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "url": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "SAVE_REPORT",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the HTTP endpoint to call (e.g., https://api.example.com).",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Makes an HTTP request with JSON-based body input.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "Simple API Request",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "make_request",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "url",
              "method",
              "body_data",
              "headers_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "SimpleAPIRequest",
          "id": "SimpleAPIRequest-2rGPs"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        }
      },
      {
        "id": "PromptInvocator-E9CV2",
        "type": "genericNode",
        "position": {
          "x": 11882.39795217151,
          "y": 252.21346528114628
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Data",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/performance-checklist",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-E9CV2"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-fYTWd",
        "type": "genericNode",
        "position": {
          "x": 10465.610612226732,
          "y": 1994.4568255579736
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Data",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/metrics",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-fYTWd"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-gDmXB",
        "type": "genericNode",
        "position": {
          "x": 9059.784297304548,
          "y": 1815.5552165645045
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/expense-table",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-gDmXB"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        },
        "dragging": false
      },
      {
        "id": "PromptInvocator-5kkkt",
        "type": "genericNode",
        "position": {
          "x": 9471.848366670783,
          "y": 1816.971818876458
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/expense-ratio",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-5kkkt"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-TydHN",
        "type": "genericNode",
        "position": {
          "x": 9496.119269081586,
          "y": 2606.976395063967
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/lease-default-scoring",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-TydHN"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "ParseData-e59m5",
        "type": "genericNode",
        "position": {
          "x": 11030.380378690503,
          "y": 601.4878262032057
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{metrics}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData",
          "id": "ParseData-e59m5"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 342
        }
      },
      {
        "id": "PromptInvocator-1eBQ1",
        "type": "genericNode",
        "position": {
          "x": 8814.60803852174,
          "y": 5432.101483070652
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Data",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/expense-chart",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-1eBQ1"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-fN1Ic",
        "type": "genericNode",
        "position": {
          "x": 8986.733349559281,
          "y": 6128.933792000938
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Data",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/summary-report",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-fN1Ic"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "Custom Webhook-K4Qz4",
        "type": "genericNode",
        "position": {
          "x": 15,
          "y": 1971.8973899917166
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass WebhookComponent(Component):\n    display_name = \"Custom Webhook\"\n    description = \"Defines a webhook input for the flow.\"\n    name = \"Custom Webhook\"\n    icon = \"webhook\"\n\n    inputs = [\n        MultilineInput(\n            name=\"data\",\n            display_name=\"Payload\",\n            info=\"Receives a payload from external systems via HTTP POST.\",\n        )\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"output_data\", method=\"build_data\"),\n        Output(display_name=\"ticker\", name=\"ticker\", method=\"build_ticker\"),\n        Output(display_name=\"criterionKey\", name=\"criterionKey\", method=\"build_criterion_key\"),\n        Output(display_name=\"reportKey\", name=\"reportKey\", method=\"build_report_key\"),\n    ]\n    \n    def build_data(self) -> Data:\n        message: str | Data = \"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return Data(data={})\n        try:\n            body = json.loads(self.data or \"{}\")\n        except json.JSONDecodeError:\n            body = {\"payload\": self.data}\n            message = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n        data = Data(data=body)\n        if not message:\n            message = data\n        self.status = message\n        return data\n\n    def _parse_payload(self) -> dict:\n        \"\"\"Helper method to parse JSON payload and handle errors.\"\"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return {}\n        try:\n            return json.loads(self.data)\n        except json.JSONDecodeError:\n            self.status = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n            # Return the raw payload under a dedicated key if needed\n            return {\"payload\": self.data}\n\n    def build_ticker(self) -> Message:\n        \"\"\"Extracts the 'ticker' value from the payload.\"\"\"\n        payload = self._parse_payload()\n        ticker = payload.get(\"ticker\", \"\")\n        return Message(text=ticker)\n\n    def build_criterion_key(self) -> Message:\n        \"\"\"Extracts the 'key' from the nested 'criterion' field.\"\"\"\n        payload = self._parse_payload()\n        criterion = payload.get(\"criterion\", {})\n        criterion_key = criterion.get(\"key\", \"\")\n        return Message(text=criterion_key)\n\n    def build_report_key(self) -> Message:\n        \"\"\"Extracts the 'reportKey' value from the payload.\"\"\"\n        payload = self._parse_payload()\n        report_key = payload.get(\"reportKey\", \"\")\n        return Message(text=report_key)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "{\n  \"ticker\": \"FVR\",\n  \"reportKey\": \"performance_and_metrics\",\n  \"criterion\": {\n  \"key\": \"operations_expense_management\",\n  \"name\": \"Operations and Expense Management\",\n  \"shortDescription\": \"Assesses the REITs operating performance and expense control through FFO, AFFO, cost efficiency, and bad debt from leases.\",\n  \"matchingInstruction\": \"Please extract the number of common stocks (shares) outstanding. Also EXTRACT ALL THE ASKED INFORMATION FOR THE LATEST QUARTER: FFO/AFFO - 1) Any quantitative data, including tables, formulas or calculation logic used to determine FFO and AFFO. 2) Any qualitative discussion or analysis relating to FFO and AFFO. All Expenses - 1) Extract all expense-related data, including any quantitative values, tables, and formulas. 2) Any qualitative notes, analysis, or commentary on expense management. Team Members - 1) Any details regarding team members, including but not limited to salaries, compensation structures, bonuses, or other relevant personnel information. Bad Debt & Lease Payment Issues - 1) Any information related to lease payment delays, tenant defaults, or rental income losses due to unpaid leases. Ignore any content that does not match these criteria.\",\n  \"importantMetrics\": [\n   {\n  \"key\": \"ffo_to_equity_ratio\",\n  \"name\": \"FFO-to-Equity Ratio\",\n  \"description\": \"The FFO-to-Equity Ratio measures how much Funds From Operations (FFO) a REIT generates relative to the common shareholders' equity. A higher ratio indicates stronger cash flow generation compared to the invested equity base, highlighting the REIT’s ability to produce operating profits from shareholder capital. Pick up the calculated value from the given data. Do not calculate it yourself. \",\n  \"formula\": \"FFO-to-Equity Ratio = [Total FFO (common stockholder) x4]÷ Total equity (common stockholder)\"\n},\n{\n  \"key\": \"expense_management_score\",\n  \"name\": \"Expense Management Score - Maintenance Variable Costs\",\n  \"description\": \"This score evaluates how efficiently a REIT manages its operational expenses, particularly maintenance and variable costs that are directly influenced by management decisions. Also for the Calculation Explanation, you have to take all the points and summary of the information that was used to come up with the final score. Do not miss any point. The score is the whole number from 1-100.\",\n  \"formula\": \"You have to pick up the final score out of 100 from the given data, you don't have to calculate it.\"\n},\n{\n  \"key\": \"price_to_ffo\",\n  \"name\": \"Price to FFO\",\n  \"description\": \"Price to FFO is a valuation ratio used for REITs that compares the market price per share to the Funds From Operations (FFO) per share. It shows how much investors are paying for each dollar of cash-based earnings. Pick up the calculated value from the given data. Do not calculate it yourself.\",\n  \"formula\": \"Price to FFO = Price per share / (FFO per share x 4)\"\n},\n{\n  \"key\": \"non_cash_expense_score\",\n  \"name\": \"Non-Cash Expense Score\",\n  \"description\": \"This score measures the proportion of non-cash expenses relative to total revenue, helping investors understand how much of the REITs reported expenses do not affect actual cash flow. Also for the Calculation Explanation, you have to take all the points and summary of the information that was used to come up with the final score. Do not miss any point. The score is the whole number from 1-100.\",\n  \"formula\": \"You have to pick up the final score out of 100 from the given data, you don't have to calculate it.\"\n},\n{\n  \"key\": \"lease_defaults_and_payment_failures\",\n  \"name\": \"Lease Defaults and Payment Failures\",\n  \"description\": \"This score assesses the REITs exposure to lost revenue due to unpaid or delayed lease payments. It reflects the REITs effectiveness in collecting rents on time and managing tenant credit risk. Also for the Calculation Explanation, you have to take all the points and summary of the information that was used to come up with the final score. Do not miss any point. The score is the whole number from 1-100.\",\n  \"formula\": \"You have to pick up the final score out of 100 from the given data, you don't have to calculate it.\"\n}\n  ],\n  \"reports\": [\n    {\n      \"key\": \"ffo_affo_summary_report\",\n      \"name\": \"FFO AFFO Summary Report\",\n      \"description\": \"Provides an in-depth text-based overview of the REITs operating performance, focusing on FFO and AFFO figures and their implications for dividend sustainability.\",\n      \"outputType\": \"Text\"\n    },\n    {\n      \"key\": \"expense_breakdown_chart\",\n      \"name\": \"Expense Breakdown Donut Chart\",\n      \"description\": \"Visualizes the composition of total expenses from the latest 10-Q filing using a donut chart, showing how each type of expense contributes to the overall expense cost.\",\n      \"outputType\": \"DoughnutChart\"\n    }\n  ],\n  \"langflowWebhookUrl\": \"https://langflow.dodao.io/api/v1/webhook/7c8cb7b4-e9c6-4fde-b0ff-b6715d1527b5\"\n}\n\n}",
                "display_name": "Payload",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Receives a payload from external systems via HTTP POST.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Defines a webhook input for the flow.",
            "icon": "webhook",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Custom Webhook",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output_data",
                "display_name": "Data",
                "method": "build_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "ticker",
                "display_name": "ticker",
                "method": "build_ticker",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "criterionKey",
                "display_name": "criterionKey",
                "method": "build_criterion_key",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "reportKey",
                "display_name": "reportKey",
                "method": "build_report_key",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "Custom Webhook",
          "id": "Custom Webhook-K4Qz4"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 373
        }
      },
      {
        "id": "Price-t2kJE",
        "type": "genericNode",
        "position": {
          "x": 10044.981745083283,
          "y": 1720.3949390802566
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output, MultilineInput\nfrom langflow.schema.message import Message\nimport requests\n\nclass PriceComponent(Component):\n    display_name = \"Price\"\n    description = \"A custom component for getting price for the given date otherwise price at reporting period of latest 10Q.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"Price\"\n\n    PRICE_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/price-at-period-of-report\"\n    \n    inputs = [\n        MessageTextInput(\n            name=\"ticker\",\n            display_name=\"Ticker\",\n            info=\"The ticker to retrieve data for (e.g., MDV, FVR).\",\n            required=True\n        ),\n        MultilineInput(\n            name=\"period_of_report\",\n            display_name=\"Date\",\n            info=\"Date to get the price at (optional).\",\n        )\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Price\",\n            name=\"text\",\n            method=\"get_price\",\n        ),\n    ]\n\n    def get_price(self) -> Message:\n        ticker = self.ticker\n        period_of_report = self.period_of_report if self.period_of_report else None\n\n        payload = {\n            \"ticker\": ticker,\n            \"period_of_report\": period_of_report,\n        }\n        try:\n            response = requests.post(self.PRICE_ENDPOINT, json=payload)\n            resp_data = response.json()\n            return Message(text=str(resp_data[\"data\"]))\n        except Exception as exc:\n            return Message(text=str(exc))\n\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "period_of_report": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "period_of_report",
                "value": "",
                "display_name": "Date",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Date to get the price at (optional).",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "ticker": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "ticker",
                "value": "",
                "display_name": "Ticker",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The ticker to retrieve data for (e.g., MDV, FVR).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for getting price for the given date otherwise price at reporting period of latest 10Q.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Price",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Price",
                "method": "get_price",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "ticker",
              "period_of_report"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "Price",
          "id": "Price-t2kJE"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 352
        }
      },
      {
        "id": "PromptInvocator-hAzF4",
        "type": "genericNode",
        "position": {
          "x": 9509.29635565416,
          "y": 3358.630044263228
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/ffo-per-share",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-hAzF4"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-lXOOT",
        "type": "genericNode",
        "position": {
          "x": 9510.261263678338,
          "y": 4104.198371160053
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/ffo-to-equity-ratio",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "dodao_sec_tools",
            "key": "PromptInvocator",
            "score": 0.007568328950209746
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-lXOOT"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-uJ7DX",
        "type": "genericNode",
        "position": {
          "x": 9556.69661632393,
          "y": 4875.889247987081
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "gpt-4o",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/operational-expense/non-cash-expense-score",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "dodao_sec_tools",
            "key": "PromptInvocator",
            "score": 0.007568328950209746
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-uJ7DX"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      }
    ],
    "edges": [
      {
        "source": "Sec10QDataExtractor-AHeLe",
        "target": "Prompt-PI1Wk",
        "sourceHandle": "{œdataTypeœ:œSec10QDataExtractorœ,œidœ:œSec10QDataExtractor-AHeLeœ,œnameœ:œmerged_sec_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œAll_Financial_Dataœ,œidœ:œPrompt-PI1Wkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Sec10QDataExtractor-AHeLe{œdataTypeœ:œSec10QDataExtractorœ,œidœ:œSec10QDataExtractor-AHeLeœ,œnameœ:œmerged_sec_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-PI1Wk{œfieldNameœ:œAll_Financial_Dataœ,œidœ:œPrompt-PI1Wkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Sec10QDataExtractor",
            "id": "Sec10QDataExtractor-AHeLe",
            "name": "merged_sec_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "All_Financial_Data",
            "id": "Prompt-PI1Wk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Sec10QDataExtractor-wVpsv",
        "target": "Prompt-PI1Wk",
        "sourceHandle": "{œdataTypeœ:œSec10QDataExtractorœ,œidœ:œSec10QDataExtractor-wVpsvœ,œnameœ:œmerged_sec_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œCriterionœ,œidœ:œPrompt-PI1Wkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Sec10QDataExtractor-wVpsv{œdataTypeœ:œSec10QDataExtractorœ,œidœ:œSec10QDataExtractor-wVpsvœ,œnameœ:œmerged_sec_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-PI1Wk{œfieldNameœ:œCriterionœ,œidœ:œPrompt-PI1Wkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Sec10QDataExtractor",
            "id": "Sec10QDataExtractor-wVpsv",
            "name": "merged_sec_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "Criterion",
            "id": "Prompt-PI1Wk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-PI1Wk",
        "target": "ConditionalRouter-NGeyN",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-PI1Wkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-NGeyNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-PI1Wk{œdataTypeœ:œPromptœ,œidœ:œPrompt-PI1Wkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-NGeyN{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-NGeyNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-PI1Wk",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-NGeyN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-PI1Wk",
        "target": "Prompt-AdYS6",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-PI1Wkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œPrompt-AdYS6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-PI1Wk{œdataTypeœ:œPromptœ,œidœ:œPrompt-PI1Wkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-AdYS6{œfieldNameœ:œdataœ,œidœ:œPrompt-AdYS6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-PI1Wk",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "Prompt-AdYS6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-NGeyN",
        "target": "Prompt-OKKM2",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-NGeyN{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt-OKKM2{œfieldNameœ:œdataœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-NGeyN",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "Prompt-OKKM2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Sec10QDataExtractor-AHeLe",
        "target": "ConditionalRouter-w9jsD",
        "sourceHandle": "{œdataTypeœ:œSec10QDataExtractorœ,œidœ:œSec10QDataExtractor-AHeLeœ,œnameœ:œmerged_sec_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-w9jsDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Sec10QDataExtractor-AHeLe{œdataTypeœ:œSec10QDataExtractorœ,œidœ:œSec10QDataExtractor-AHeLeœ,œnameœ:œmerged_sec_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-w9jsD{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-w9jsDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Sec10QDataExtractor",
            "id": "Sec10QDataExtractor-AHeLe",
            "name": "merged_sec_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-w9jsD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-PI1Wk",
        "target": "ConditionalRouter-bUTeX",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-PI1Wkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-bUTeXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-PI1Wk{œdataTypeœ:œPromptœ,œidœ:œPrompt-PI1Wkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-bUTeX{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-bUTeXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-PI1Wk",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-bUTeX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-E9CV2",
        "target": "SimpleAPIRequest-OZt8Y",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-E9CV2œ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-OZt8Yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-PromptInvocator-E9CV2{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-E9CV2œ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}-SimpleAPIRequest-OZt8Y{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-OZt8Yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-E9CV2",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "body_data",
            "id": "SimpleAPIRequest-OZt8Y",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-OKKM2",
        "target": "PromptInvocator-fYTWd",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-OKKM2œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-fYTWdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-OKKM2{œdataTypeœ:œPromptœ,œidœ:œPrompt-OKKM2œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-fYTWd{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-fYTWdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-OKKM2",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-fYTWd",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-fYTWd",
        "target": "SimpleAPIRequest-ESO4j",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-fYTWdœ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-ESO4jœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-PromptInvocator-fYTWd{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-fYTWdœ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}-SimpleAPIRequest-ESO4j{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-ESO4jœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-fYTWd",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "body_data",
            "id": "SimpleAPIRequest-ESO4j",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-NGeyN",
        "target": "PromptInvocator-gDmXB",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-gDmXBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-NGeyN{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-gDmXB{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-gDmXBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-NGeyN",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-gDmXB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-gDmXB",
        "target": "PromptInvocator-5kkkt",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-gDmXBœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-5kkktœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-PromptInvocator-gDmXB{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-gDmXBœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-5kkkt{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-5kkktœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-gDmXB",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-5kkkt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-5kkkt",
        "target": "Prompt-OKKM2",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-5kkktœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œexpenses_ratioœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-PromptInvocator-5kkkt{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-5kkktœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-OKKM2{œfieldNameœ:œexpenses_ratioœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-5kkkt",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "expenses_ratio",
            "id": "Prompt-OKKM2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-NGeyN",
        "target": "PromptInvocator-TydHN",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-TydHNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-NGeyN{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-TydHN{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-TydHNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-NGeyN",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-TydHN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-TydHN",
        "target": "Prompt-OKKM2",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-TydHNœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œlease_defaultœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-PromptInvocator-TydHN{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-TydHNœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-OKKM2{œfieldNameœ:œlease_defaultœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-TydHN",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "lease_default",
            "id": "Prompt-OKKM2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ParseData-e59m5",
        "target": "Prompt-AdYS6",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-e59m5œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œmetricsValuesœ,œidœ:œPrompt-AdYS6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ParseData-e59m5{œdataTypeœ:œParseDataœ,œidœ:œParseData-e59m5œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-AdYS6{œfieldNameœ:œmetricsValuesœ,œidœ:œPrompt-AdYS6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-e59m5",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "metricsValues",
            "id": "Prompt-AdYS6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-fYTWd",
        "target": "ParseData-e59m5",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-fYTWdœ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-e59m5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-PromptInvocator-fYTWd{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-fYTWdœ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}-ParseData-e59m5{œfieldNameœ:œdataœ,œidœ:œParseData-e59m5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-fYTWd",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-e59m5",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-AdYS6",
        "target": "PromptInvocator-E9CV2",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-AdYS6œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-E9CV2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-AdYS6{œdataTypeœ:œPromptœ,œidœ:œPrompt-AdYS6œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-E9CV2{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-E9CV2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-AdYS6",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-E9CV2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-w9jsD",
        "target": "PromptInvocator-1eBQ1",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-w9jsDœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-1eBQ1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-w9jsD{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-w9jsDœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-1eBQ1{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-1eBQ1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-w9jsD",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-1eBQ1",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-1eBQ1",
        "target": "SimpleAPIRequest-QMuQt",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-1eBQ1œ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-QMuQtœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-PromptInvocator-1eBQ1{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-1eBQ1œ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}-SimpleAPIRequest-QMuQt{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-QMuQtœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-1eBQ1",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "body_data",
            "id": "SimpleAPIRequest-QMuQt",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-bUTeX",
        "target": "PromptInvocator-fN1Ic",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-bUTeXœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-fN1Icœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-bUTeX{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-bUTeXœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-fN1Ic{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-fN1Icœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-bUTeX",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-fN1Ic",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-fN1Ic",
        "target": "SimpleAPIRequest-2rGPs",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-fN1Icœ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-2rGPsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-PromptInvocator-fN1Ic{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-fN1Icœ,œnameœ:œinvocation_outputœ,œoutput_typesœ:[œDataœ]}-SimpleAPIRequest-2rGPs{œfieldNameœ:œbody_dataœ,œidœ:œSimpleAPIRequest-2rGPsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-fN1Ic",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "body_data",
            "id": "SimpleAPIRequest-2rGPs",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "Sec10QDataExtractor-wVpsv",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œcriterionKeyœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œcriterion_keyœ,œidœ:œSec10QDataExtractor-wVpsvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œcriterionKeyœ,œoutput_typesœ:[œMessageœ]}-Sec10QDataExtractor-wVpsv{œfieldNameœ:œcriterion_keyœ,œidœ:œSec10QDataExtractor-wVpsvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "criterionKey",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "criterion_key",
            "id": "Sec10QDataExtractor-wVpsv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "ConditionalRouter-NGeyN",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œreportKeyœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-NGeyNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œreportKeyœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-NGeyN{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-NGeyNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "reportKey",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-NGeyN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "ConditionalRouter-w9jsD",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œreportKeyœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-w9jsDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œreportKeyœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-w9jsD{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-w9jsDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "reportKey",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-w9jsD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "ConditionalRouter-bUTeX",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œreportKeyœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-bUTeXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œreportKeyœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-bUTeX{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-bUTeXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "reportKey",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-bUTeX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "Sec10QDataExtractor-wVpsv",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œtickerœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œtickerœ,œidœ:œSec10QDataExtractor-wVpsvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œtickerœ,œoutput_typesœ:[œMessageœ]}-Sec10QDataExtractor-wVpsv{œfieldNameœ:œtickerœ,œidœ:œSec10QDataExtractor-wVpsvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "ticker",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ticker",
            "id": "Sec10QDataExtractor-wVpsv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "Sec10QDataExtractor-AHeLe",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œtickerœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œtickerœ,œidœ:œSec10QDataExtractor-AHeLeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œtickerœ,œoutput_typesœ:[œMessageœ]}-Sec10QDataExtractor-AHeLe{œfieldNameœ:œtickerœ,œidœ:œSec10QDataExtractor-AHeLeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "ticker",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ticker",
            "id": "Sec10QDataExtractor-AHeLe",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "PromptInvocator-E9CV2",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-E9CV2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}-PromptInvocator-E9CV2{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-E9CV2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-E9CV2",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "PromptInvocator-1eBQ1",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-1eBQ1œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}-PromptInvocator-1eBQ1{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-1eBQ1œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-1eBQ1",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "PromptInvocator-fN1Ic",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-fN1Icœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}-PromptInvocator-fN1Ic{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-fN1Icœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-fN1Ic",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "PromptInvocator-fYTWd",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-fYTWdœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œoutput_dataœ,œoutput_typesœ:[œDataœ]}-PromptInvocator-fYTWd{œfieldNameœ:œinput_jsonœ,œidœ:œPromptInvocator-fYTWdœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-fYTWd",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-K4Qz4",
        "target": "Price-t2kJE",
        "sourceHandle": "{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œtickerœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œtickerœ,œidœ:œPrice-t2kJEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Custom Webhook-K4Qz4{œdataTypeœ:œCustom Webhookœ,œidœ:œCustom Webhook-K4Qz4œ,œnameœ:œtickerœ,œoutput_typesœ:[œMessageœ]}-Price-t2kJE{œfieldNameœ:œtickerœ,œidœ:œPrice-t2kJEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-K4Qz4",
            "name": "ticker",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ticker",
            "id": "Price-t2kJE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Price-t2kJE",
        "target": "Prompt-OKKM2",
        "sourceHandle": "{œdataTypeœ:œPriceœ,œidœ:œPrice-t2kJEœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œpriceœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Price-t2kJE{œdataTypeœ:œPriceœ,œidœ:œPrice-t2kJEœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-OKKM2{œfieldNameœ:œpriceœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Price",
            "id": "Price-t2kJE",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "price",
            "id": "Prompt-OKKM2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-NGeyN",
        "target": "PromptInvocator-hAzF4",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-hAzF4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-NGeyN{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-hAzF4{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-hAzF4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-NGeyN",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-hAzF4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-hAzF4",
        "target": "Prompt-OKKM2",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-hAzF4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œffo_per_shareœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-PromptInvocator-hAzF4{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-hAzF4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-OKKM2{œfieldNameœ:œffo_per_shareœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-hAzF4",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ffo_per_share",
            "id": "Prompt-OKKM2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-NGeyN",
        "target": "PromptInvocator-lXOOT",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-lXOOTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-NGeyN{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-lXOOT{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-lXOOTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-NGeyN",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-lXOOT",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-lXOOT",
        "target": "Prompt-OKKM2",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-lXOOTœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œffo_to_equity_ratioœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-PromptInvocator-lXOOT{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-lXOOTœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-OKKM2{œfieldNameœ:œffo_to_equity_ratioœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-lXOOT",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ffo_to_equity_ratio",
            "id": "Prompt-OKKM2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-NGeyN",
        "target": "PromptInvocator-uJ7DX",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-uJ7DXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ConditionalRouter-NGeyN{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-NGeyNœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-PromptInvocator-uJ7DX{œfieldNameœ:œbody_to_appendœ,œidœ:œPromptInvocator-uJ7DXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-NGeyN",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-uJ7DX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-uJ7DX",
        "target": "Prompt-OKKM2",
        "sourceHandle": "{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-uJ7DXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œnon_cash_expense_scoreœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-PromptInvocator-uJ7DX{œdataTypeœ:œPromptInvocatorœ,œidœ:œPromptInvocator-uJ7DXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-OKKM2{œfieldNameœ:œnon_cash_expense_scoreœ,œidœ:œPrompt-OKKM2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-uJ7DX",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "non_cash_expense_score",
            "id": "Prompt-OKKM2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": 61.02886361291087,
      "y": 26.317509533130874,
      "zoom": 0.08991392956678881
    }
  }
}