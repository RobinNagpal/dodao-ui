{
  "icon_bg_color": null,
  "user_id": "0be3e4c3-3b27-440f-81e4-921ccf9df0b3",
  "gradient": null,
  "icon": null,
  "is_component": false,
  "tags": null,
  "updated_at": "2025-08-06T14:15:04+00:00",
  "locked": false,
  "webhook": true,
  "folder_id": "00af9b7e-c33a-4fbf-8396-9739dbc109f2",
  "endpoint_name": null,
  "description": "Connect the Dots, Craft Language.",
  "id": "68419246-4078-4648-ab57-712eb2cc4a08",
  "name": "Shareholder v4",
  "data": {
    "nodes": [
      {
        "id": "Prompt-3ftH8",
        "type": "genericNode",
        "position": {
          "x": 2242.731777838827,
          "y": 2510.290680061752
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "## All Financial Statements:\n\nNote: All values are Dollar $ amounts\n\n{All_Financial_Data}\n\n---------------------------------------------------\n\n## Related Information from SEC 10Q Filing:\n\n{Criterion}\n\n\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "Criterion": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "Criterion",
                "display_name": "Criterion",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "All_Financial_Data": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "All_Financial_Data",
                "display_name": "All_Financial_Data",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "All_Financial_Data",
                "Criterion"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-3ftH8"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 420
        }
      },
      {
        "id": "SimpleAPIRequest-hWTTJ",
        "type": "genericNode",
        "position": {
          "x": 8760.514586152596,
          "y": 1902.68167044791
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "body_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_data",
                "value": "",
                "display_name": "Body (JSON Data)",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Parsed JSON from the JSONPayloadComponent (or any Data).",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\r\nimport asyncio\r\nfrom typing import Any, Dict\r\n\r\nimport httpx\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (\r\n    StrInput,\r\n    DropdownInput,\r\n    DataInput,\r\n    Output,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass SimpleAPIRequestComponent(Component):\r\n    display_name = \"Simple API Request\"\r\n    description = \"Makes an HTTP request with JSON-based body input.\"\r\n    icon = \"Globe\"\r\n    name = \"SimpleAPIRequest\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"Enter the HTTP endpoint to call (e.g., https://api.example.com).\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\r\n            info=\"Select the HTTP method to use.\",\r\n        ),\r\n        DataInput(\r\n            name=\"body_data\",\r\n            display_name=\"Body (JSON Data)\",\r\n            info=\"Parsed JSON from the JSONPayloadComponent (or any Data).\",\r\n            advanced=False,\r\n        ),\r\n        TableInput(\r\n            name=\"headers_data\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary.\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Header\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header value\",\r\n                },\r\n            ],\r\n            value=[],\r\n            advanced=True,\r\n            input_types=[\"Data\"],\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Response\", name=\"response\", method=\"make_request\"),\r\n    ]\r\n\r\n    async def make_request(self) -> Data:\r\n        \"\"\"Executes an HTTP request using the provided URL, method, body_data, and headers_data.\"\"\"\r\n        url = self.url\r\n        method = self.method.upper()\r\n\r\n        # Extract the actual data from the Data objects\r\n        # If \"body_data\" was from JSONPayloadComponent, it might be a dict or a string.\r\n        # We'll assume dictionary is intended for JSON body. If it's something else, handle gracefully.\r\n        body_content = self.body_data.data if self.body_data else None\r\n        if not isinstance(body_content, (dict, list)) and body_content is not None:\r\n            # If it's a plain string or something else, wrap it or parse it as needed\r\n            # For a real app, you could refine this logic. For now, we'll just send it as-is.\r\n            body_content = {\"data\": body_content}\r\n\r\n        # Same for headers\r\n        headers = {}\r\n        if self.headers_data and isinstance(self.headers_data.data, dict):\r\n            # Convert all header values to strings just to be safe\r\n            headers = {str(k): str(v) for k, v in self.headers_data.data.items()}\r\n\r\n        try:\r\n            async with httpx.AsyncClient() as client:\r\n                if method in {\"GET\", \"DELETE\"}:\r\n                    # GET/DELETE usually send no JSON body\r\n                    response = await client.request(method, url, headers=headers)\r\n                else:\r\n                    response = await client.request(method, url, headers=headers, json=body_content)\r\n\r\n                # Attempt to parse the response as JSON\r\n                try:\r\n                    resp_data = response.json()\r\n                except json.JSONDecodeError:\r\n                    # If not valid JSON, just return the raw text\r\n                    resp_data = {\"raw_text\": response.text}\r\n\r\n                return Data(\r\n                    data={\r\n                        \"status_code\": response.status_code,\r\n                        \"response\": resp_data,\r\n                    }\r\n                )\r\n\r\n        except Exception as exc:\r\n            # If there's a network error, timeouts, etc., return an error structure\r\n            return Data(\r\n                    data={\r\n                        \"status_code\": 500,\r\n                        \"response\": str(exc),\r\n                    }\r\n                )\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "headers_data": {
                "tool_mode": false,
                "is_list": true,
                "list_add_label": "Add More",
                "table_schema": {
                  "columns": [
                    {
                      "name": "key",
                      "display_name": "Header",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header name",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    },
                    {
                      "name": "value",
                      "display_name": "Value",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header value",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    }
                  ]
                },
                "trigger_text": "Open table",
                "trigger_icon": "Table",
                "table_icon": "Table",
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "headers_data",
                "value": [],
                "display_name": "Headers",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "method": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "method",
                "value": "POST",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "Select the HTTP method to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "url": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "SAVE_METRICS",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the HTTP endpoint to call (e.g., https://api.example.com).",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Makes an HTTP request with JSON-based body input.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "Simple API Request",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "make_request",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "url",
              "method",
              "body_data",
              "headers_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "SimpleAPIRequest",
          "id": "SimpleAPIRequest-hWTTJ"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        }
      },
      {
        "id": "SimpleAPIRequest-vSli7",
        "type": "genericNode",
        "position": {
          "x": 11226.274821158648,
          "y": 378.20056951466904
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "body_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_data",
                "value": "",
                "display_name": "Body (JSON Data)",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Parsed JSON from the JSONPayloadComponent (or any Data).",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\r\nimport asyncio\r\nfrom typing import Any, Dict\r\n\r\nimport httpx\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (\r\n    StrInput,\r\n    DropdownInput,\r\n    DataInput,\r\n    Output,\r\n)\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass SimpleAPIRequestComponent(Component):\r\n    display_name = \"Simple API Request\"\r\n    description = \"Makes an HTTP request with JSON-based body input.\"\r\n    icon = \"Globe\"\r\n    name = \"SimpleAPIRequest\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"Enter the HTTP endpoint to call (e.g., https://api.example.com).\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\r\n            info=\"Select the HTTP method to use.\",\r\n        ),\r\n        DataInput(\r\n            name=\"body_data\",\r\n            display_name=\"Body (JSON Data)\",\r\n            info=\"Parsed JSON from the JSONPayloadComponent (or any Data).\",\r\n            advanced=False,\r\n        ),\r\n        TableInput(\r\n            name=\"headers_data\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary.\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Header\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header value\",\r\n                },\r\n            ],\r\n            value=[],\r\n            advanced=True,\r\n            input_types=[\"Data\"],\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Response\", name=\"response\", method=\"make_request\"),\r\n    ]\r\n\r\n    async def make_request(self) -> Data:\r\n        \"\"\"Executes an HTTP request using the provided URL, method, body_data, and headers_data.\"\"\"\r\n        url = self.url\r\n        method = self.method.upper()\r\n\r\n        # Extract the actual data from the Data objects\r\n        # If \"body_data\" was from JSONPayloadComponent, it might be a dict or a string.\r\n        # We'll assume dictionary is intended for JSON body. If it's something else, handle gracefully.\r\n        body_content = self.body_data.data if self.body_data else None\r\n        if not isinstance(body_content, (dict, list)) and body_content is not None:\r\n            # If it's a plain string or something else, wrap it or parse it as needed\r\n            # For a real app, you could refine this logic. For now, we'll just send it as-is.\r\n            body_content = {\"data\": body_content}\r\n\r\n        # Same for headers\r\n        headers = {}\r\n        if self.headers_data and isinstance(self.headers_data.data, dict):\r\n            # Convert all header values to strings just to be safe\r\n            headers = {str(k): str(v) for k, v in self.headers_data.data.items()}\r\n\r\n        try:\r\n            async with httpx.AsyncClient() as client:\r\n                if method in {\"GET\", \"DELETE\"}:\r\n                    # GET/DELETE usually send no JSON body\r\n                    response = await client.request(method, url, headers=headers)\r\n                else:\r\n                    response = await client.request(method, url, headers=headers, json=body_content)\r\n\r\n                # Attempt to parse the response as JSON\r\n                try:\r\n                    resp_data = response.json()\r\n                except json.JSONDecodeError:\r\n                    # If not valid JSON, just return the raw text\r\n                    resp_data = {\"raw_text\": response.text}\r\n\r\n                return Data(\r\n                    data={\r\n                        \"status_code\": response.status_code,\r\n                        \"response\": resp_data,\r\n                    }\r\n                )\r\n\r\n        except Exception as exc:\r\n            # If there's a network error, timeouts, etc., return an error structure\r\n            return Data(\r\n                    data={\r\n                        \"status_code\": 500,\r\n                        \"response\": str(exc),\r\n                    }\r\n                )\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "headers_data": {
                "tool_mode": false,
                "is_list": true,
                "list_add_label": "Add More",
                "table_schema": {
                  "columns": [
                    {
                      "name": "key",
                      "display_name": "Header",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header name",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    },
                    {
                      "name": "value",
                      "display_name": "Value",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Header value",
                      "disable_edit": false,
                      "edit_mode": "modal",
                      "hidden": false
                    }
                  ]
                },
                "trigger_text": "Open table",
                "trigger_icon": "Table",
                "table_icon": "Table",
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "headers_data",
                "value": [],
                "display_name": "Headers",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "method": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "method",
                "value": "POST",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "Select the HTTP method to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "url": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "SAVE_PERFORMANCE_CHECKLIST",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the HTTP endpoint to call (e.g., https://api.example.com).",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Makes an HTTP request with JSON-based body input.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "Simple API Request",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "make_request",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "url",
              "method",
              "body_data",
              "headers_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "SimpleAPIRequest",
          "id": "SimpleAPIRequest-vSli7"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        }
      },
      {
        "id": "Sec10QDataExtractor-pRNyS",
        "type": "genericNode",
        "position": {
          "x": 1731.1969044096995,
          "y": 1991.0377002498687
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\nfrom langflow.io import MessageTextInput, Output\n\nimport requests\nimport json\n\n\"\"\"\nThis module defines a single custom component (`SecEdgarMergedComponent`) that merges\nthree different \"tools\" or functionalities for retrieving SEC 10-Q filings data:\n\n1) **All Financials (mode='all_financials')**  \n   - Retrieves the full 10-Q XBRL-based financial statements for a given ticker.\n\n2) **Specific 10-Q Report (mode='specific_report')**  \n   - Retrieves a specific part of the 10-Q for a given ticker.  \n   - e.g. 'balance_sheet', 'income_statement', etc.\n\n3) **Criteria-Related Info (mode='criteria_related_info')**  \n   - Retrieves data related to a given \"criterion\" (e.g., 'debt', 'rent') in the 10-Q.\n\n-------------------------------------------------------------------------------\nExample System Prompt (to guide the LLM on how to choose the 'mode' & inputs):\n\n\"You have a single custom SEC 10-Q data extractor tool that has 3 possible modes:\n1) 'all_financials' for full 10-Q financial data,\n2) 'specific_report' for a specific 10-Q section (balance_sheet, income_statement, etc.),\n3) 'criteria_related_info' for retrieving specific criteria.\n\nWhen a user asks for the full 10-Q financial statements, set mode='all_financials'.\nWhen a user asks for a specific statement, set mode='specific_report' and fill 'report_type'.\nWhen a user asks for a custom criterion, set mode='criteria_related_info' and fill 'criterion_key'.\nAlways set 'ticker' according to the user's request.\"\n\n-------------------------------------------------------------------------------\nExample User Prompts that will route to the correct mode:\n\n1) \"Give me the info of debt criteria of AMT in sec filing.\"\n   \"Find me info on lease obligations for AMT's latest 10-Q.\"\n   -> mode='criteria_related_info', ticker='AMT', criterion_key='debt'\n\n2) \"Give me all financial details of AMT stock in sec filing.\"\n   \"Please fetch all 10-Q financial data for AMT.\"\n   -> mode='all_financials', ticker='AMT'\n\n3) \"Give me balance sheet of AMT stock in sec filing.\"\n   \"Show me the balance sheet of AMT's latest 10-Q.\"\n   -> mode='specific_report', ticker='AMT', report_type='balance_sheet'\n\n-------------------------------------------------------------------------------\n\"\"\"\n\nclass SecEdgarMergedComponent(Component):\n    display_name = \"SEC 10-Q Data\"\n    description = \"A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"Sec10QDataExtractor\"\n\n    FINANCIALS_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/financials\"\n    SEARCH_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/search\"\n    CRITERIA_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/get-matching-criteria-attachments\"\n    \n    inputs = [\n        MessageTextInput(\n            name=\"ticker\",\n            display_name=\"Ticker\",\n            value=\"AAPL\",\n            info=\"The stock ticker symbol (e.g. AAPL).\",\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"all_financials\", \"specific_report\", \"criteria_related_info\"],\n            info=(\n                \"Select 'all_financials' to retrieve the full 10Q XBRL-based data.\\n\"\n                \"Select 'specific_report' to retrieve a specific part of the 10Q.\\n\"\n                \"Select 'criteria_related_info' to retrieve specific criterion data from the 10Q.\"\n            ),\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"report_type\",\n            display_name=\"Report Type (Used if mode='specific_report')\",\n            value=\"\",\n            info=\"E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"criterion_key\",\n            display_name=\"Criterion Key (Used if mode='criteria_related_info')\",\n            value=\"\",\n            info=\"Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Merged SEC Output\",\n            name=\"merged_sec_output\",\n            method=\"call_merged_tool\",\n        )\n    ]\n\n    def call_merged_tool(self) -> Message:\n        \"\"\"\n        Decide which underlying call to run based on 'mode'.\n        For PART 1, we'll return placeholder text.\n        Replace this with real Lambda calls in PART 2.\n        \"\"\"\n\n        ticker = self.ticker\n        mode = self.mode\n        report_type = self.report_type\n        criterion_key = self.criterion_key\n\n        if mode == \"all_financials\":\n            return self._call_all_financials(ticker)\n\n        elif mode == \"specific_report\":\n            return self._call_specific_report(ticker, report_type)\n        \n        elif mode == \"criteria_related_info\":\n            return self._call_criteria_info(ticker, criterion_key)\n\n        else:\n            return Message(\n                text=(\n                    f\"You selected mode '{mode}', which isn't implemented yet.\\n\"\n                    \"In the future, we can add new routes or logic here.\"\n                )\n            )\n\n    def _call_all_financials(self, ticker: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker}\n            response = requests.post(self.FINANCIALS_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/financials): {e}\"\n            return Message(text=error_text)\n\n    def _call_specific_report(self, ticker: str, report_type: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"report_type\": report_type}\n            response = requests.post(self.SEARCH_ENDPOINT, json=payload)\n            data = response.json()  \n\n            message_text = data.get(\"data\", \"\")\n            return Message(text=message_text)\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/search): {e}\"\n            return Message(text=error_text)\n\n    def _call_criteria_info(self, ticker: str, criterion_key: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"criterion_key\": criterion_key}\n            response = requests.post(self.CRITERIA_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/get-matching-criteria-attachments): {e}\"\n            return Message(text=error_text)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "criterion_key": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "criterion_key",
                "value": "",
                "display_name": "Criterion Key (Used if mode='criteria_related_info')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mode": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "all_financials",
                  "specific_report",
                  "criteria_related_info"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mode",
                "value": "all_financials",
                "display_name": "Mode",
                "advanced": false,
                "dynamic": false,
                "info": "Select 'all_financials' to retrieve the full 10Q XBRL-based data.\nSelect 'specific_report' to retrieve a specific part of the 10Q.\nSelect 'criteria_related_info' to retrieve specific criterion data from the 10Q.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "report_type": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "report_type",
                "value": "",
                "display_name": "Report Type (Used if mode='specific_report')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "ticker": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ticker",
                "value": "",
                "display_name": "Ticker",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The stock ticker symbol (e.g. AAPL).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "SEC 10-Q Data",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "merged_sec_output",
                "hidden": null,
                "display_name": "Merged SEC Output",
                "method": "call_merged_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "ticker",
              "mode",
              "report_type",
              "criterion_key"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "Sec10QDataExtractor",
          "id": "Sec10QDataExtractor-pRNyS"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 517
        }
      },
      {
        "id": "Sec10QDataExtractor-emSLP",
        "type": "genericNode",
        "position": {
          "x": 1742.4291494889685,
          "y": 2732.495739387872
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\nfrom langflow.io import MessageTextInput, Output\n\nimport requests\nimport json\n\n\"\"\"\nThis module defines a single custom component (`SecEdgarMergedComponent`) that merges\nthree different \"tools\" or functionalities for retrieving SEC 10-Q filings data:\n\n1) **All Financials (mode='all_financials')**  \n   - Retrieves the full 10-Q XBRL-based financial statements for a given ticker.\n\n2) **Specific 10-Q Report (mode='specific_report')**  \n   - Retrieves a specific part of the 10-Q for a given ticker.  \n   - e.g. 'balance_sheet', 'income_statement', etc.\n\n3) **Criteria-Related Info (mode='criteria_related_info')**  \n   - Retrieves data related to a given \"criterion\" (e.g., 'debt', 'rent') in the 10-Q.\n\n-------------------------------------------------------------------------------\nExample System Prompt (to guide the LLM on how to choose the 'mode' & inputs):\n\n\"You have a single custom SEC 10-Q data extractor tool that has 3 possible modes:\n1) 'all_financials' for full 10-Q financial data,\n2) 'specific_report' for a specific 10-Q section (balance_sheet, income_statement, etc.),\n3) 'criteria_related_info' for retrieving specific criteria.\n\nWhen a user asks for the full 10-Q financial statements, set mode='all_financials'.\nWhen a user asks for a specific statement, set mode='specific_report' and fill 'report_type'.\nWhen a user asks for a custom criterion, set mode='criteria_related_info' and fill 'criterion_key'.\nAlways set 'ticker' according to the user's request.\"\n\n-------------------------------------------------------------------------------\nExample User Prompts that will route to the correct mode:\n\n1) \"Give me the info of debt criteria of AMT in sec filing.\"\n   \"Find me info on lease obligations for AMT's latest 10-Q.\"\n   -> mode='criteria_related_info', ticker='AMT', criterion_key='debt'\n\n2) \"Give me all financial details of AMT stock in sec filing.\"\n   \"Please fetch all 10-Q financial data for AMT.\"\n   -> mode='all_financials', ticker='AMT'\n\n3) \"Give me balance sheet of AMT stock in sec filing.\"\n   \"Show me the balance sheet of AMT's latest 10-Q.\"\n   -> mode='specific_report', ticker='AMT', report_type='balance_sheet'\n\n-------------------------------------------------------------------------------\n\"\"\"\n\nclass SecEdgarMergedComponent(Component):\n    display_name = \"SEC 10-Q Data\"\n    description = \"A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"Sec10QDataExtractor\"\n\n    FINANCIALS_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/financials\"\n    SEARCH_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/search\"\n    CRITERIA_ENDPOINT = \"https://4mbhgkl77s4gubn7i2rdcllbru0wzyxl.lambda-url.us-east-1.on.aws/get-matching-criteria-attachments\"\n    \n    inputs = [\n        MessageTextInput(\n            name=\"ticker\",\n            display_name=\"Ticker\",\n            value=\"AAPL\",\n            info=\"The stock ticker symbol (e.g. AAPL).\",\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"all_financials\", \"specific_report\", \"criteria_related_info\"],\n            info=(\n                \"Select 'all_financials' to retrieve the full 10Q XBRL-based data.\\n\"\n                \"Select 'specific_report' to retrieve a specific part of the 10Q.\\n\"\n                \"Select 'criteria_related_info' to retrieve specific criterion data from the 10Q.\"\n            ),\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"report_type\",\n            display_name=\"Report Type (Used if mode='specific_report')\",\n            value=\"\",\n            info=\"E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"criterion_key\",\n            display_name=\"Criterion Key (Used if mode='criteria_related_info')\",\n            value=\"\",\n            info=\"Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Merged SEC Output\",\n            name=\"merged_sec_output\",\n            method=\"call_merged_tool\",\n        )\n    ]\n\n    def call_merged_tool(self) -> Message:\n        \"\"\"\n        Decide which underlying call to run based on 'mode'.\n        For PART 1, we'll return placeholder text.\n        Replace this with real Lambda calls in PART 2.\n        \"\"\"\n\n        ticker = self.ticker\n        mode = self.mode\n        report_type = self.report_type\n        criterion_key = self.criterion_key\n\n        if mode == \"all_financials\":\n            return self._call_all_financials(ticker)\n\n        elif mode == \"specific_report\":\n            return self._call_specific_report(ticker, report_type)\n        \n        elif mode == \"criteria_related_info\":\n            return self._call_criteria_info(ticker, criterion_key)\n\n        else:\n            return Message(\n                text=(\n                    f\"You selected mode '{mode}', which isn't implemented yet.\\n\"\n                    \"In the future, we can add new routes or logic here.\"\n                )\n            )\n\n    def _call_all_financials(self, ticker: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker}\n            response = requests.post(self.FINANCIALS_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/financials): {e}\"\n            return Message(text=error_text)\n\n    def _call_specific_report(self, ticker: str, report_type: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"report_type\": report_type}\n            response = requests.post(self.SEARCH_ENDPOINT, json=payload)\n            data = response.json()  \n\n            message_text = data.get(\"data\", \"\")\n            return Message(text=message_text)\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/search): {e}\"\n            return Message(text=error_text)\n\n    def _call_criteria_info(self, ticker: str, criterion_key: str) -> Message:\n        try:\n            payload = {\"ticker\": ticker, \"criterion_key\": criterion_key}\n            response = requests.post(self.CRITERIA_ENDPOINT, json=payload)\n            response_data = response.json()  \n\n            if \"message\" in response_data:\n                return Message(text=response_data[\"message\"])\n            elif \"data\" in response_data:\n                return Message(text=response_data[\"data\"])\n            else:\n                return Message(text=json.dumps(response_data, indent=2))\n\n        except Exception as e:\n            error_text = f\"Error calling SEC Edgar Lambda (/get-matching-criteria-attachments): {e}\"\n            return Message(text=error_text)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "criterion_key": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "criterion_key",
                "value": "",
                "display_name": "Criterion Key (Used if mode='criteria_related_info')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the criterion key to retrieve e.g. 'debt', 'rent', etc.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mode": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "all_financials",
                  "specific_report",
                  "criteria_related_info"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mode",
                "value": "criteria_related_info",
                "display_name": "Mode",
                "advanced": false,
                "dynamic": false,
                "info": "Select 'all_financials' to retrieve the full 10Q XBRL-based data.\nSelect 'specific_report' to retrieve a specific part of the 10Q.\nSelect 'criteria_related_info' to retrieve specific criterion data from the 10Q.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "report_type": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "report_type",
                "value": "",
                "display_name": "Report Type (Used if mode='specific_report')",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "E.g.: 'balance_sheet', 'income_statement', 'operation_statement', or 'cash_flow'.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "ticker": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ticker",
                "value": "",
                "display_name": "Ticker",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The stock ticker symbol (e.g. AAPL).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for retrieving financial statements, specific reports, or criteria information from SEC 10-Q filings.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "SEC 10-Q Data",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "merged_sec_output",
                "hidden": null,
                "display_name": "Merged SEC Output",
                "method": "call_merged_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "ticker",
              "mode",
              "report_type",
              "criterion_key"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "Sec10QDataExtractor",
          "id": "Sec10QDataExtractor-emSLP"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 517
        }
      },
      {
        "id": "note-uZnZK",
        "type": "noteNode",
        "position": {
          "x": 9960.892706352937,
          "y": 45
        },
        "data": {
          "node": {
            "description": "# Performance Checklist",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-uZnZK"
        },
        "selected": false,
        "measured": {
          "width": 325,
          "height": 324
        }
      },
      {
        "id": "note-pgfoG",
        "type": "noteNode",
        "position": {
          "x": 7821.279588200967,
          "y": 1198.1050963092532
        },
        "data": {
          "node": {
            "description": "# Important Metrics",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-pgfoG"
        },
        "selected": false,
        "measured": {
          "width": 325,
          "height": 324
        }
      },
      {
        "id": "ConditionalRouter-uPK3e",
        "type": "genericNode",
        "position": {
          "x": 4662.168596515257,
          "y": 811.566245768328
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "case_sensitive",
                "value": false,
                "display_name": "Case Sensitive",
                "advanced": false,
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_route": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_route",
                "value": "false_result",
                "display_name": "Default Route",
                "advanced": true,
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "input_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "match_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "match_text",
                "value": "performance_and_metrics",
                "display_name": "Match Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text input to compare against.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 10,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "message": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to pass through either route.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "operator": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "operator",
                "value": "contains",
                "display_name": "Operator",
                "advanced": false,
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "icon": "split",
            "base_classes": [
              "Message"
            ],
            "display_name": "If-Else",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "true_result",
                "hidden": null,
                "display_name": "True",
                "method": "true_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "false_result",
                "hidden": null,
                "display_name": "False",
                "method": "false_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "logic",
            "key": "ConditionalRouter",
            "score": 0.001,
            "lf_version": "1.1.4.dev13"
          },
          "showNode": true,
          "type": "ConditionalRouter",
          "id": "ConditionalRouter-uPK3e"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 588
        }
      },
      {
        "id": "Prompt-IzgFK",
        "type": "genericNode",
        "position": {
          "x": 7798.348263510425,
          "y": 1614.3446143995795
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Here is the data:\n\n# JV and Off Balance Sheet Score:\n\n{jv_and_off_balance_sheet_score}\n\n#  FFO Payout Ratio to Common Shareholders :\n\n{ffo_payout_ratio_to_common_shareholders}\n\n# Shareholder Dividend\n\n{share_holder_dividend}\n\n# Common Shareholder Weightage \n\n{common_shareholder_weightage}\n\n# Return on Equity\n\n{return_on_equity}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "jv_and_off_balance_sheet_score": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "jv_and_off_balance_sheet_score",
                "display_name": "jv_and_off_balance_sheet_score",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "share_holder_dividend": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "share_holder_dividend",
                "display_name": "share_holder_dividend",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "common_shareholder_weightage": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "common_shareholder_weightage",
                "display_name": "common_shareholder_weightage",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "return_on_equity": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "return_on_equity",
                "display_name": "return_on_equity",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "ffo_payout_ratio_to_common_shareholders": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "ffo_payout_ratio_to_common_shareholders",
                "display_name": "ffo_payout_ratio_to_common_shareholders",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "jv_and_off_balance_sheet_score",
                "ffo_payout_ratio_to_common_shareholders",
                "share_holder_dividend",
                "common_shareholder_weightage",
                "return_on_equity"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-IzgFK"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 667
        }
      },
      {
        "id": "Prompt-aIzOy",
        "type": "genericNode",
        "position": {
          "x": 10371.435591658856,
          "y": 371.67281105488746
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "# Metric Values\n\nHere are the calculated values of the metrics:\n\n {metricsValues}\n\n# Data \n\nHere is the financial information and the raw information from SEC 10Q filing:\n\n{data}\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "data": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "data",
                "display_name": "data",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "metricsValues": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "metricsValues",
                "display_name": "metricsValues",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "metricsValues",
                "data"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-aIzOy"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 420
        }
      },
      {
        "id": "ParseData-l91ma",
        "type": "genericNode",
        "position": {
          "x": 9975.723529211518,
          "y": 474.1451250529883
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{metrics}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.01857804455091699
          },
          "showNode": true,
          "type": "ParseData",
          "id": "ParseData-l91ma"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 342
        }
      },
      {
        "id": "ChatOutput-gpP6q",
        "type": "genericNode",
        "position": {
          "x": 8797.054967688748,
          "y": 1766.0164410221025
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if not isinstance(self.input_value, Data | DataFrame | Message | str | list):\n            msg = f\"Expected Data or DataFrame or Message or str, got {type(self.input_value).__name__}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput",
          "id": "ChatOutput-gpP6q"
        },
        "selected": false,
        "measured": {
          "width": 192,
          "height": 66
        }
      },
      {
        "id": "ChatOutput-CkF9R",
        "type": "genericNode",
        "position": {
          "x": 11268.37921512841,
          "y": 239.35330700176587
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if not isinstance(self.input_value, Data | DataFrame | Message | str | list):\n            msg = f\"Expected Data or DataFrame or Message or str, got {type(self.input_value).__name__}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput",
          "id": "ChatOutput-CkF9R"
        },
        "selected": false,
        "measured": {
          "width": 192,
          "height": 66
        }
      },
      {
        "id": "PromptInvocator-XfeQ6",
        "type": "genericNode",
        "position": {
          "x": 6896.845842104332,
          "y": 1242.4014004528885
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/ffo-payout-ratio-to-common-shareholders",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-XfeQ6"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-jJff6",
        "type": "genericNode",
        "position": {
          "x": 6514.751280167532,
          "y": 2008.627336561863
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/dividend",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-jJff6"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-OZbLc",
        "type": "genericNode",
        "position": {
          "x": 6938.711751153218,
          "y": 1990.7998570650334
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/shareholder-dividend",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-OZbLc"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-p2O2E",
        "type": "genericNode",
        "position": {
          "x": 6965.086676562151,
          "y": 2783.975354213833
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/common-shareholder-weightage",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-p2O2E"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-zXCLZ",
        "type": "genericNode",
        "position": {
          "x": 6971.441928808141,
          "y": 3584.3935194463998
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/jv-and-off-balance-sheet-score",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-zXCLZ"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-swyyS",
        "type": "genericNode",
        "position": {
          "x": 6970.137072949881,
          "y": 4419.722499991565
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Message",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/return-on-equity",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-swyyS"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-jYDyN",
        "type": "genericNode",
        "position": {
          "x": 8207.219024224565,
          "y": 1612.0417464996617
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Data",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/metrics",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-jYDyN"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "PromptInvocator-iBBoW",
        "type": "genericNode",
        "position": {
          "x": 10815.060511702177,
          "y": 116.09837986159991
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_json": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_json",
                "value": "",
                "display_name": "Input Json",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to send to the prompt invocation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "OpenAI"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "LLM Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "body_to_append": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body_to_append",
                "value": "",
                "display_name": "Body To Append",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Body to be appended after the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.inputs import DropdownInput\nfrom langflow.io import MessageTextInput, Output, DataInput, MultilineInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.helpers.data import data_to_text\nimport requests\nimport json\n\nclass PromptInvocatorComponent(Component):\n    display_name = \"Prompt Invocator\"\n    description = \"A custom component for running a prompt using a prompt key.\"\n    documentation = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"PromptInvocator\"\n\n    KOALAGAINS_INVOCATION_ENDPOINT = \"https://koalagains.com/api/actions/prompt-invocation/full-req-resp\"\n    \n    inputs = [\n        DataInput(\n            name=\"input_json\",\n            display_name=\"Input Json\",\n            info=\"The data to send to the prompt invocation.\",\n        ),\n        MessageTextInput(\n            name=\"prompt_key\",\n            display_name=\"Prompt Key\",\n            info=\"The key added when creating the prompt.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"LLM Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"gpt-4o-mini\", \"gpt-4o\", \"o3-mini\", \"o4-mini\"],\n            value=\"gpt-4o\",\n        ),\n        MultilineInput(\n            name=\"body_to_append\",\n            display_name=\"Body To Append\",\n            info=\"Body to be appended after the prompt.\",\n        ),\n        DropdownInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Data\", \"Message\"],\n            value=\"Data\",\n            info=\"Select the type of output returned by the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"invocation_output\",\n            method=\"output_data\",\n        ),\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"output_message\",\n        ),\n    ]\n\n    def call_prompt_invocator(self) -> Data:\n        \"\"\"Calls the API and returns the raw Data output.\"\"\"\n        input_json = self.input_json.data if self.input_json and self.input_json.data else {}\n        prompt_key = self.prompt_key\n        agent_llm = self.agent_llm\n        model = self.model\n        body_to_append = self.body_to_append\n\n        payload = {\n            \"inputJson\": input_json,\n            \"promptKey\": prompt_key,\n            \"llmProvider\": agent_llm,\n            \"model\": model,\n            \"bodyToAppend\": body_to_append,\n            \"requestFrom\": \"langflow\"\n        }\n        try:\n            response = requests.post(self.KOALAGAINS_INVOCATION_ENDPOINT, json=payload)\n            try:\n                resp_data = response.json()\n            except json.JSONDecodeError:\n                resp_data = {\"raw_text\": response.text}\n            return Data(data=resp_data)\n        except Exception as exc:\n            return Data(data={\"error\": str(exc)})\n\n    def output_data(self) -> Data:\n        if self.output_type == \"Data\":\n            return self.call_prompt_invocator()\n        return Data(data={})\n\n    def output_message(self) -> Message:\n        if self.output_type == \"Message\":\n            data = self.call_prompt_invocator()\n            try:\n                text = data_to_text(\"{message}\", data)\n                return Message(text=text)\n            except Exception as exc:\n                return Message(text=str(exc))\n        return Message(text=\"\")\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "o3-mini",
                  "o4-mini"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "o4-mini",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "output_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Data",
                  "Message"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_type",
                "value": "Data",
                "display_name": "Output Type",
                "advanced": false,
                "dynamic": false,
                "info": "Select the type of output returned by the component.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "prompt_key",
                "value": "US/public-equities/real-estate/equity-reits/share-holder-alignment/performance-checklist",
                "display_name": "Prompt Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The key added when creating the prompt.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "A custom component for running a prompt using a prompt key.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Prompt Invocator",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "invocation_output",
                "hidden": null,
                "display_name": "Data",
                "method": "output_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "output_message",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_json",
              "prompt_key",
              "agent_llm",
              "model",
              "body_to_append",
              "output_type"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptInvocator",
          "id": "PromptInvocator-iBBoW"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        }
      },
      {
        "id": "Custom Webhook-vT1sN",
        "type": "genericNode",
        "position": {
          "x": 15,
          "y": 2430
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass WebhookComponent(Component):\n    display_name = \"Custom Webhook\"\n    description = \"Defines a webhook input for the flow.\"\n    name = \"Custom Webhook\"\n    icon = \"webhook\"\n\n    inputs = [\n        MultilineInput(\n            name=\"data\",\n            display_name=\"Payload\",\n            info=\"Receives a payload from external systems via HTTP POST.\",\n        )\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"output_data\", method=\"build_data\"),\n        Output(display_name=\"ticker\", name=\"ticker\", method=\"build_ticker\"),\n        Output(display_name=\"criterionKey\", name=\"criterionKey\", method=\"build_criterion_key\"),\n        Output(display_name=\"reportKey\", name=\"reportKey\", method=\"build_report_key\"),\n    ]\n    \n    def build_data(self) -> Data:\n        message: str | Data = \"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return Data(data={})\n        try:\n            body = json.loads(self.data or \"{}\")\n        except json.JSONDecodeError:\n            body = {\"payload\": self.data}\n            message = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n        data = Data(data=body)\n        if not message:\n            message = data\n        self.status = message\n        return data\n\n    def _parse_payload(self) -> dict:\n        \"\"\"Helper method to parse JSON payload and handle errors.\"\"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return {}\n        try:\n            return json.loads(self.data)\n        except json.JSONDecodeError:\n            self.status = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n            # Return the raw payload under a dedicated key if needed\n            return {\"payload\": self.data}\n\n    def build_ticker(self) -> Message:\n        \"\"\"Extracts the 'ticker' value from the payload.\"\"\"\n        payload = self._parse_payload()\n        ticker = payload.get(\"ticker\", \"\")\n        return Message(text=ticker)\n\n    def build_criterion_key(self) -> Message:\n        \"\"\"Extracts the 'key' from the nested 'criterion' field.\"\"\"\n        payload = self._parse_payload()\n        criterion = payload.get(\"criterion\", {})\n        criterion_key = criterion.get(\"key\", \"\")\n        return Message(text=criterion_key)\n\n    def build_report_key(self) -> Message:\n        \"\"\"Extracts the 'reportKey' value from the payload.\"\"\"\n        payload = self._parse_payload()\n        report_key = payload.get(\"reportKey\", \"\")\n        return Message(text=report_key)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Payload",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Receives a payload from external systems via HTTP POST.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Defines a webhook input for the flow.",
            "icon": "webhook",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Custom Webhook",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output_data",
                "display_name": "Data",
                "method": "build_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "ticker",
                "display_name": "ticker",
                "method": "build_ticker",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "criterionKey",
                "display_name": "criterionKey",
                "method": "build_criterion_key",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "reportKey",
                "display_name": "reportKey",
                "method": "build_report_key",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Custom Webhook",
          "id": "Custom Webhook-vT1sN"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 373
        }
      }
    ],
    "edges": [
      {
        "source": "Sec10QDataExtractor-pRNyS",
        "target": "Prompt-3ftH8",
        "sourceHandle": "{dataType:Sec10QDataExtractor,id:Sec10QDataExtractor-pRNyS,name:merged_sec_output,output_types:[Message]}",
        "targetHandle": "{fieldName:All_Financial_Data,id:Prompt-3ftH8,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Sec10QDataExtractor-pRNyS{dataType:Sec10QDataExtractor,id:Sec10QDataExtractor-pRNyS,name:merged_sec_output,output_types:[Message]}-Prompt-3ftH8{fieldName:All_Financial_Data,id:Prompt-3ftH8,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Sec10QDataExtractor",
            "id": "Sec10QDataExtractor-pRNyS",
            "name": "merged_sec_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "All_Financial_Data",
            "id": "Prompt-3ftH8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Sec10QDataExtractor-emSLP",
        "target": "Prompt-3ftH8",
        "sourceHandle": "{dataType:Sec10QDataExtractor,id:Sec10QDataExtractor-emSLP,name:merged_sec_output,output_types:[Message]}",
        "targetHandle": "{fieldName:Criterion,id:Prompt-3ftH8,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Sec10QDataExtractor-emSLP{dataType:Sec10QDataExtractor,id:Sec10QDataExtractor-emSLP,name:merged_sec_output,output_types:[Message]}-Prompt-3ftH8{fieldName:Criterion,id:Prompt-3ftH8,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Sec10QDataExtractor",
            "id": "Sec10QDataExtractor-emSLP",
            "name": "merged_sec_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "Criterion",
            "id": "Prompt-3ftH8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-3ftH8",
        "target": "ConditionalRouter-uPK3e",
        "sourceHandle": "{dataType:Prompt,id:Prompt-3ftH8,name:prompt,output_types:[Message]}",
        "targetHandle": "{fieldName:message,id:ConditionalRouter-uPK3e,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Prompt-3ftH8{dataType:Prompt,id:Prompt-3ftH8,name:prompt,output_types:[Message]}-ConditionalRouter-uPK3e{fieldName:message,id:ConditionalRouter-uPK3e,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-3ftH8",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-uPK3e",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-3ftH8",
        "target": "Prompt-aIzOy",
        "sourceHandle": "{dataType:Prompt,id:Prompt-3ftH8,name:prompt,output_types:[Message]}",
        "targetHandle": "{fieldName:data,id:Prompt-aIzOy,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Prompt-3ftH8{dataType:Prompt,id:Prompt-3ftH8,name:prompt,output_types:[Message]}-Prompt-aIzOy{fieldName:data,id:Prompt-aIzOy,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-3ftH8",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "Prompt-aIzOy",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ParseData-l91ma",
        "target": "Prompt-aIzOy",
        "sourceHandle": "{dataType:ParseData,id:ParseData-l91ma,name:text,output_types:[Message]}",
        "targetHandle": "{fieldName:metricsValues,id:Prompt-aIzOy,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-ParseData-l91ma{dataType:ParseData,id:ParseData-l91ma,name:text,output_types:[Message]}-Prompt-aIzOy{fieldName:metricsValues,id:Prompt-aIzOy,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-l91ma",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "metricsValues",
            "id": "Prompt-aIzOy",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-uPK3e",
        "target": "PromptInvocator-jJff6",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-jJff6,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-ConditionalRouter-uPK3e{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}-PromptInvocator-jJff6{fieldName:body_to_append,id:PromptInvocator-jJff6,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-uPK3e",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-jJff6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-jJff6",
        "target": "PromptInvocator-OZbLc",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-jJff6,name:text,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-OZbLc,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-PromptInvocator-jJff6{dataType:PromptInvocator,id:PromptInvocator-jJff6,name:text,output_types:[Message]}-PromptInvocator-OZbLc{fieldName:body_to_append,id:PromptInvocator-OZbLc,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-jJff6",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-OZbLc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-OZbLc",
        "target": "Prompt-IzgFK",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-OZbLc,name:text,output_types:[Message]}",
        "targetHandle": "{fieldName:share_holder_dividend,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-PromptInvocator-OZbLc{dataType:PromptInvocator,id:PromptInvocator-OZbLc,name:text,output_types:[Message]}-Prompt-IzgFK{fieldName:share_holder_dividend,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-OZbLc",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "share_holder_dividend",
            "id": "Prompt-IzgFK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-uPK3e",
        "target": "PromptInvocator-p2O2E",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-p2O2E,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-ConditionalRouter-uPK3e{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}-PromptInvocator-p2O2E{fieldName:body_to_append,id:PromptInvocator-p2O2E,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-uPK3e",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-p2O2E",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-p2O2E",
        "target": "Prompt-IzgFK",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-p2O2E,name:text,output_types:[Message]}",
        "targetHandle": "{fieldName:common_shareholder_weightage,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-PromptInvocator-p2O2E{dataType:PromptInvocator,id:PromptInvocator-p2O2E,name:text,output_types:[Message]}-Prompt-IzgFK{fieldName:common_shareholder_weightage,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-p2O2E",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "common_shareholder_weightage",
            "id": "Prompt-IzgFK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-uPK3e",
        "target": "PromptInvocator-zXCLZ",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-zXCLZ,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-ConditionalRouter-uPK3e{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}-PromptInvocator-zXCLZ{fieldName:body_to_append,id:PromptInvocator-zXCLZ,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-uPK3e",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-zXCLZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-zXCLZ",
        "target": "Prompt-IzgFK",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-zXCLZ,name:text,output_types:[Message]}",
        "targetHandle": "{fieldName:jv_and_off_balance_sheet_score,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-PromptInvocator-zXCLZ{dataType:PromptInvocator,id:PromptInvocator-zXCLZ,name:text,output_types:[Message]}-Prompt-IzgFK{fieldName:jv_and_off_balance_sheet_score,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-zXCLZ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "jv_and_off_balance_sheet_score",
            "id": "Prompt-IzgFK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-uPK3e",
        "target": "PromptInvocator-swyyS",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-swyyS,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-ConditionalRouter-uPK3e{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}-PromptInvocator-swyyS{fieldName:body_to_append,id:PromptInvocator-swyyS,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-uPK3e",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-swyyS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-IzgFK",
        "target": "PromptInvocator-jYDyN",
        "sourceHandle": "{dataType:Prompt,id:Prompt-IzgFK,name:prompt,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-jYDyN,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Prompt-IzgFK{dataType:Prompt,id:Prompt-IzgFK,name:prompt,output_types:[Message]}-PromptInvocator-jYDyN{fieldName:body_to_append,id:PromptInvocator-jYDyN,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-IzgFK",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-jYDyN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-jYDyN",
        "target": "ChatOutput-gpP6q",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-jYDyN,name:invocation_output,output_types:[Data]}",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-gpP6q,inputTypes:[Data,DataFrame,Message],type:other}",
        "id": "reactflow__edge-PromptInvocator-jYDyN{dataType:PromptInvocator,id:PromptInvocator-jYDyN,name:invocation_output,output_types:[Data]}-ChatOutput-gpP6q{fieldName:input_value,id:ChatOutput-gpP6q,inputTypes:[Data,DataFrame,Message],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-jYDyN",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-gpP6q",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-jYDyN",
        "target": "SimpleAPIRequest-hWTTJ",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-jYDyN,name:invocation_output,output_types:[Data]}",
        "targetHandle": "{fieldName:body_data,id:SimpleAPIRequest-hWTTJ,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-PromptInvocator-jYDyN{dataType:PromptInvocator,id:PromptInvocator-jYDyN,name:invocation_output,output_types:[Data]}-SimpleAPIRequest-hWTTJ{fieldName:body_data,id:SimpleAPIRequest-hWTTJ,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-jYDyN",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "body_data",
            "id": "SimpleAPIRequest-hWTTJ",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-jYDyN",
        "target": "ParseData-l91ma",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-jYDyN,name:invocation_output,output_types:[Data]}",
        "targetHandle": "{fieldName:data,id:ParseData-l91ma,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-PromptInvocator-jYDyN{dataType:PromptInvocator,id:PromptInvocator-jYDyN,name:invocation_output,output_types:[Data]}-ParseData-l91ma{fieldName:data,id:ParseData-l91ma,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-jYDyN",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-l91ma",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-aIzOy",
        "target": "PromptInvocator-iBBoW",
        "sourceHandle": "{dataType:Prompt,id:Prompt-aIzOy,name:prompt,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-iBBoW,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Prompt-aIzOy{dataType:Prompt,id:Prompt-aIzOy,name:prompt,output_types:[Message]}-PromptInvocator-iBBoW{fieldName:body_to_append,id:PromptInvocator-iBBoW,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-aIzOy",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-iBBoW",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-iBBoW",
        "target": "ChatOutput-CkF9R",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-iBBoW,name:invocation_output,output_types:[Data]}",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-CkF9R,inputTypes:[Data,DataFrame,Message],type:other}",
        "id": "reactflow__edge-PromptInvocator-iBBoW{dataType:PromptInvocator,id:PromptInvocator-iBBoW,name:invocation_output,output_types:[Data]}-ChatOutput-CkF9R{fieldName:input_value,id:ChatOutput-CkF9R,inputTypes:[Data,DataFrame,Message],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-iBBoW",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-CkF9R",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-iBBoW",
        "target": "SimpleAPIRequest-vSli7",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-iBBoW,name:invocation_output,output_types:[Data]}",
        "targetHandle": "{fieldName:body_data,id:SimpleAPIRequest-vSli7,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-PromptInvocator-iBBoW{dataType:PromptInvocator,id:PromptInvocator-iBBoW,name:invocation_output,output_types:[Data]}-SimpleAPIRequest-vSli7{fieldName:body_data,id:SimpleAPIRequest-vSli7,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-iBBoW",
            "name": "invocation_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "body_data",
            "id": "SimpleAPIRequest-vSli7",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-swyyS",
        "target": "Prompt-IzgFK",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-swyyS,name:text,output_types:[Message]}",
        "targetHandle": "{fieldName:return_on_equity,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-PromptInvocator-swyyS{dataType:PromptInvocator,id:PromptInvocator-swyyS,name:text,output_types:[Message]}-Prompt-IzgFK{fieldName:return_on_equity,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-swyyS",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "return_on_equity",
            "id": "Prompt-IzgFK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "Sec10QDataExtractor-pRNyS",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:ticker,output_types:[Message]}",
        "targetHandle": "{fieldName:ticker,id:Sec10QDataExtractor-pRNyS,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:ticker,output_types:[Message]}-Sec10QDataExtractor-pRNyS{fieldName:ticker,id:Sec10QDataExtractor-pRNyS,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "ticker",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ticker",
            "id": "Sec10QDataExtractor-pRNyS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "Sec10QDataExtractor-emSLP",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:criterionKey,output_types:[Message]}",
        "targetHandle": "{fieldName:criterion_key,id:Sec10QDataExtractor-emSLP,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:criterionKey,output_types:[Message]}-Sec10QDataExtractor-emSLP{fieldName:criterion_key,id:Sec10QDataExtractor-emSLP,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "criterionKey",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "criterion_key",
            "id": "Sec10QDataExtractor-emSLP",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "Sec10QDataExtractor-emSLP",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:ticker,output_types:[Message]}",
        "targetHandle": "{fieldName:ticker,id:Sec10QDataExtractor-emSLP,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:ticker,output_types:[Message]}-Sec10QDataExtractor-emSLP{fieldName:ticker,id:Sec10QDataExtractor-emSLP,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "ticker",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ticker",
            "id": "Sec10QDataExtractor-emSLP",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "ConditionalRouter-uPK3e",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:reportKey,output_types:[Message]}",
        "targetHandle": "{fieldName:input_text,id:ConditionalRouter-uPK3e,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:reportKey,output_types:[Message]}-ConditionalRouter-uPK3e{fieldName:input_text,id:ConditionalRouter-uPK3e,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "reportKey",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-uPK3e",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-XfeQ6",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-XfeQ6,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-XfeQ6{fieldName:input_json,id:PromptInvocator-XfeQ6,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-XfeQ6",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-jJff6",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-jJff6,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-jJff6{fieldName:input_json,id:PromptInvocator-jJff6,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-jJff6",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-OZbLc",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-OZbLc,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-OZbLc{fieldName:input_json,id:PromptInvocator-OZbLc,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-OZbLc",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-p2O2E",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-p2O2E,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-p2O2E{fieldName:input_json,id:PromptInvocator-p2O2E,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-p2O2E",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-swyyS",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-swyyS,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-swyyS{fieldName:input_json,id:PromptInvocator-swyyS,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-swyyS",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-zXCLZ",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-zXCLZ,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-zXCLZ{fieldName:input_json,id:PromptInvocator-zXCLZ,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-zXCLZ",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-jYDyN",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-jYDyN,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-jYDyN{fieldName:input_json,id:PromptInvocator-jYDyN,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-jYDyN",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "Custom Webhook-vT1sN",
        "target": "PromptInvocator-iBBoW",
        "sourceHandle": "{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}",
        "targetHandle": "{fieldName:input_json,id:PromptInvocator-iBBoW,inputTypes:[Data],type:other}",
        "id": "reactflow__edge-Custom Webhook-vT1sN{dataType:Custom Webhook,id:Custom Webhook-vT1sN,name:output_data,output_types:[Data]}-PromptInvocator-iBBoW{fieldName:input_json,id:PromptInvocator-iBBoW,inputTypes:[Data],type:other}",
        "data": {
          "sourceHandle": {
            "dataType": "Custom Webhook",
            "id": "Custom Webhook-vT1sN",
            "name": "output_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_json",
            "id": "PromptInvocator-iBBoW",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "ConditionalRouter-uPK3e",
        "target": "PromptInvocator-XfeQ6",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}",
        "targetHandle": "{fieldName:body_to_append,id:PromptInvocator-XfeQ6,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-ConditionalRouter-uPK3e{dataType:ConditionalRouter,id:ConditionalRouter-uPK3e,name:true_result,output_types:[Message]}-PromptInvocator-XfeQ6{fieldName:body_to_append,id:PromptInvocator-XfeQ6,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-uPK3e",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "body_to_append",
            "id": "PromptInvocator-XfeQ6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      },
      {
        "source": "PromptInvocator-XfeQ6",
        "target": "Prompt-IzgFK",
        "sourceHandle": "{dataType:PromptInvocator,id:PromptInvocator-XfeQ6,name:text,output_types:[Message]}",
        "targetHandle": "{fieldName:ffo_payout_ratio_to_common_shareholders,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "id": "reactflow__edge-PromptInvocator-XfeQ6{dataType:PromptInvocator,id:PromptInvocator-XfeQ6,name:text,output_types:[Message]}-Prompt-IzgFK{fieldName:ffo_payout_ratio_to_common_shareholders,id:Prompt-IzgFK,inputTypes:[Message],type:str}",
        "data": {
          "sourceHandle": {
            "dataType": "PromptInvocator",
            "id": "PromptInvocator-XfeQ6",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ffo_payout_ratio_to_common_shareholders",
            "id": "Prompt-IzgFK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": 55.60562034418308,
      "y": 79.78181510671087,
      "zoom": 0.09901924978173864
    }
  }
}